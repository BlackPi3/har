# HPO for Scenario5 (MMD + Contrastive domain adaptation) on UTD
# scenario5 = scenario2 + MMD loss + Contrastive loss (no discriminator)
# Stable domain alignment without adversarial training instability
#
# Multi-pass HPO Strategy:
# - Pass 1: Loss weights + MMD/Contrastive params (most impactful)
# - Pass 2: Regularization (after fixing pass 1 winners)
# - Pass 3: Capacity (after fixing pass 1+2 winners)

study_name: scenario5_utd
trial: scenario5_utd  # includes mmd.enabled=true, contrastive.enabled=true

# HPO-specific overrides (shorter epochs for faster search)
trainer:
  epochs: 30
  patience: 30

top_k: 10
save_artifacts: true  # Save plots/history for each trial

repeat:
  enabled: false
  count: 5

hydra:
  sweeper:
    study_name: ${study_name}
    storage: "sqlite:///experiments/hpo/${study_name}/${study_name}.db"
    params:

      # ============================================================
      # PASS 1: Loss weights + MMD/Contrastive params (ACTIVE)
      # ============================================================
      trainer.alpha: choice(0.5, 1.0, 2.0)
      trainer.beta: choice(0, 2, 5)  # May reduce since MMD handles alignment
      trainer.gamma: choice(0.5, 1.0, 2.0)

      # MMD-specific params
      trainer.mmd.weight: choice(0.3, 0.5, 1.0)
      trainer.mmd.kernel_mul: choice(2.0)
      trainer.mmd.kernel_num: choice(5)

      # Contrastive-specific params
      trainer.contrastive.weight: choice(0.1, 0.3, 0.5)
      trainer.contrastive.temperature: choice(0.3, 0.5, 0.7)

      data.stride_seconds: choice(0.02, 0.03, 0.04)
      data.batch_size: choice(16, 24, 32)  # Larger batches help contrastive

      # --- Pass 1 DEFAULTS for Pass 2+3 params ---
      optim.lr: choice(0.001)
      optim.weight_decay: choice(0.00002)
      optim.warmup_epochs: choice(10)
      optim.scheduler.patience: choice(15)
      optim.scheduler.factor: choice(0.1)
      model.encoder_classifier.feature_extractor.drop_prob: choice(0.2)
      model.encoder_classifier.classifier.dropout: choice(0.3)
      trainer.label_smoothing: choice(0.0)

      model.encoder_classifier.feature_extractor.kernel_size: choice(9)
      model.encoder_classifier.feature_extractor.base_filters: choice([9,15,24])
      model.encoder_classifier.feature_extractor.embedding_dim: choice(100)
      model.encoder_classifier.classifier.hidden_units: choice([100])
      model.regressor.joint_hidden_channels: choice([32,32,32,16])
      model.regressor.temporal_hidden_channels: choice(16)

      # ============================================================
      # PASS 2: Regularization (UNCOMMENT after Pass 1)
      # ============================================================
      # # Fix Pass 1 winners here:
      # trainer.alpha: choice(WINNER)
      # trainer.beta: choice(WINNER)
      # trainer.gamma: choice(WINNER)
      # trainer.mmd.weight: choice(WINNER)
      # trainer.contrastive.weight: choice(WINNER)
      # trainer.contrastive.temperature: choice(WINNER)
      # data.stride_seconds: choice(WINNER)
      # data.batch_size: choice(WINNER)

      # # Search regularization:
      # optim.lr: tag(log, interval(5e-4, 2e-3))
      # optim.weight_decay: tag(log, interval(1e-5, 1e-4))
      # optim.warmup_epochs: choice(0, 5, 10)
      # optim.scheduler.patience: choice(10, 15, 20)
      # optim.scheduler.factor: choice(0.05, 0.1, 0.2)
      # model.encoder_classifier.feature_extractor.drop_prob: choice(0.1, 0.2, 0.3)
      # model.encoder_classifier.classifier.dropout: choice(0.2, 0.3, 0.4)
      # trainer.label_smoothing: choice(0.0, 0.05, 0.1)

      # # Keep capacity defaults
      # model.encoder_classifier.feature_extractor.kernel_size: choice(9)
      # model.encoder_classifier.feature_extractor.base_filters: choice([9,15,24])
      # model.encoder_classifier.feature_extractor.embedding_dim: choice(100)
      # model.encoder_classifier.classifier.hidden_units: choice([100])
      # model.regressor.joint_hidden_channels: choice([32,32,32,16])
      # model.regressor.temporal_hidden_channels: choice(16)

      # ============================================================
      # PASS 3: Capacity (UNCOMMENT after Pass 2)
      # ============================================================
      # # Fix Pass 1+2 winners here:
      # trainer.alpha: choice(WINNER)
      # trainer.beta: choice(WINNER)
      # trainer.gamma: choice(WINNER)
      # trainer.mmd.weight: choice(WINNER)
      # trainer.contrastive.weight: choice(WINNER)
      # trainer.contrastive.temperature: choice(WINNER)
      # data.stride_seconds: choice(WINNER)
      # data.batch_size: choice(WINNER)
      # optim.lr: choice(WINNER)
      # optim.weight_decay: choice(WINNER)
      # optim.warmup_epochs: choice(WINNER)
      # optim.scheduler.patience: choice(WINNER)
      # optim.scheduler.factor: choice(WINNER)
      # model.encoder_classifier.feature_extractor.drop_prob: choice(WINNER)
      # model.encoder_classifier.classifier.dropout: choice(WINNER)
      # trainer.label_smoothing: choice(WINNER)
      #
      # # Search capacity:
      # model.encoder_classifier.feature_extractor.kernel_size: choice(5, 7, 9)
      # model.encoder_classifier.feature_extractor.base_filters: choice([6,9,12], [8,12,16], [9,15,24])
      # model.encoder_classifier.feature_extractor.embedding_dim: choice(64, 80, 100)
      # model.encoder_classifier.classifier.hidden_units: choice([64], [100], [64,64])
      # model.regressor.joint_hidden_channels: choice([24,24,16,12], [32,32,24,16], [32,32,32,16])
      # model.regressor.temporal_hidden_channels: choice(10, 12, 16)

  sweep:
    dir: "experiments/hpo/${study_name}/trials"
    subdir: trial_${hydra.job.num}
