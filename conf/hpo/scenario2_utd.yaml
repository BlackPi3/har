# Per-scenario, per-dataset search space for Hydra Optuna Sweeper
# Activate with: -m hydra/sweeper=optuna hpo=scenario2_utd

# This file declares the search space (params) and the objective.

study_name: scenario2_utd
trial: scenario2_utd

# Trainer selection for this HPO space
trainer:
  name: scenario2
  epochs: 40
  patience: 40

# Number of top configs to keep for re-evaluation/reporting
top_k: 5

# Optional repeats for top-config evaluation
repeat:
  enabled: true
  count: 5

hydra:
  sweeper:
    # Study name with a robust fallback: prefer env STUDY_NAME, else this file's canonical name
    study_name: ${study_name}
    # Store Optuna DB alongside trials inside the repo
    storage: "sqlite:///experiments/hpo/${study_name}/${study_name}.db"
    params:

      # 1- Regularization pass [DONE]
      optim.lr: choice(9e-4) # FIXED tag(log,interval(1e-4,1e-3))
      optim.weight_decay: choice(2e-5) # FIXED tag(log,interval(1e-5, 1e-4))

      optim.warmup_epochs: choice(5) # FIXED choice(5, 10, 15)
      optim.warmup_start_factor: choice(0.02) # FIXED choice(0.05, 0.02)
      
      optim.scheduler.patience: choice(10) # FIXED choice(5, 10, 15)
      optim.scheduler.factor: choice(0.1, 0.3) # NARROWED choice(0.1, 0.2, 0.3)

      model.encoder_classifier.classifier.dropout: choice(0.4) # FIXED choice(0.3, 0.4, 0.5, 0.6)

      # 2- Capacity pass
      model.encoder_classifier.feature_extractor.kernel_size: choice(7, 9)
      model.encoder_classifier.feature_extractor.base_filters: choice([8, 12, 16], [9, 12, 16]) # CHANGED choice([6,9,12], [9, 12, 16])
      model.encoder_classifier.feature_extractor.embedding_dim: choice(100) # FIXED choice(64, 80, 100)

      model.encoder_classifier.classifier.hidden_units: choice([64], [64, 64]) # choice([64], [100])

      model.regressor.joint_hidden_channels: choice([24,24,16,12], [32,32,24,16])
      model.regressor.temporal_hidden_channels: choice(10, 12) # LOWERED choice(12, 16)
      model.regressor.joint_kernel_sizes: choice([3, 3, 3, 1]) # FIXED choice([3, 3, 3, 1], [5,5,3,1])
      
      # 3- Fine
      trainer.alpha: choice(0.2, 0.5, 1)
      trainer.beta: choice(0.5, 1, 2)
      trainer.gamma: choice(0.5, 1, 2)

      trainer.label_smoothing: choice(0.0, 0.05, 0.1)

      data.stride_seconds: choice (0.08, 0.1)
      data.batch_size: choice(32, 48, 64)

  sweep:
    dir: "experiments/hpo/${study_name}/trials"
    subdir: trial_${hydra.job.num}
