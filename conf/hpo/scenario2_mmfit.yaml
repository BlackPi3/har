# Per-scenario, per-dataset search space for Hydra Optuna Sweeper
# Activate with: -m hydra/sweeper=optuna hpo=scenario2_mmfit

# This file declares the search space (params) and the objective.

study_name: scenario2_mmfit
trial: scenario2_mmfit

# Trainer selection for this HPO space
trainer:
  name: scenario2
  epochs: 60
  patience: 15

hydra:
  sweeper:
    # Study name with a robust fallback: prefer env STUDY_NAME, else this file's canonical name
    study_name: ${study_name}
    # Store Optuna DB alongside trials inside the repo
    storage: "sqlite:///experiments/hpo/${study_name}/${study_name}.db"
    params:
      # Optimizer
      optim.lr: choice(1e-3, 5e-4)
      optim.weight_decay: choice(5e-4, 1e-5)
      # optim.warmup_epochs: choice(3, 4, 5, 6, 8)
      # optim.warmup_start_factor: choice(0.05, 0.1, 0.15, 0.2)
      # optim.scheduler.patience: choice(10, 20, 30, 40)

      # Trainer
      # trainer.patience: choice(20, 25, 30)
      trainer.gradient_clip: choice(null, 1.0)

      # Scenario2-specific loss coefficients
      trial.alpha: choice(0.1, 1, 10)
      trial.beta: choice(0.1, 1, 10)
      trial.gamma: choice(0.1, 1, 10)

      # Data
      data.batch_size: choice(64, 128)

      # Model 
      # model.feature_extractor.n_filters: range(8, 32, 4)
      # model.feature_extractor.filter_size: range(3, 9, 2)
      # model.regressor.joint_hidden_channels: choice([32, 32, 32, 16], [48, 48, 32, 16], [64, 64, 32, 32])
      # model.regressor.joint_kernel_sizes: choice([3, 3, 3, 1], [5, 5, 5, 1], [7, 5, 3, 1])
      # model.regressor.joint_dilations: choice([1, 2, 4, 1], [1, 3, 5, 1])
      # model.regressor.joint_dropouts: choice([0.0, 0.1, 0.1, 0.1], [0.0, 0.2, 0.2, 0.2], [0.1, 0.3, 0.3, 0.3])
      # model.regressor.temporal_hidden_channels: choice(16, 24, 32, 48)
      # model.regressor.temporal_kernel_size: choice(3, 5, 7)
      # model.regressor.temporal_dilation: choice(1, 2, 3)
      # model.regressor.temporal_dropout: choice(0.1, 0.2, 0.3, 0.4, 0.5)
      # model.regressor.fc_hidden: choice(0, 64, 128)
      # model.regressor.fc_dropout: choice(0.05, 0.1, 0.15, 0.2, 0.25)
      # model.regressor.use_batch_norm: choice(true, false)
      # TODO I don't see any hyperparams for classifier. shouldn't we search that space too?

  sweep:
    # Place all trials under a unified per-study directory
    dir: "experiments/hpo/${study_name}/trials"
    subdir: trial_${hydra.job.num}

# Optional repeats for top-config evaluation
repeat:
  enabled: false
  count: 1

# Number of top configs to keep for re-evaluation/reporting
top_k: 1
