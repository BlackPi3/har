epochs: 100
patience: 10

# Execution (formerly trainer_backend)
accelerator: auto          # auto | cpu | gpu | mps
devices: 1                 # int or list
precision: 32              # 16 | 32 | bf16
deterministic: true
log_every_n_steps: 50
gradient_clip_val: null    # e.g. 1.0 to enable
enable_checkpointing: true
logger: false              # future: wandb | tensorboard | false

# Speed knobs per epoch (1.0 means use 100% of the data)
# Use smaller fractions for faster, approximate epochs, e.g., 0.1
limit_train_batches: 1.0
limit_val_batches: 1.0
limit_test_batches: 1.0

wandb:
  enabled: false
  project: har
  entity: null
  group: null
  name: null
  tags: []
  mode: online  # online | offline | disabled
  save_code: true

early_stopping:
  enabled: true
  monitor: val_f1
  mode: max
  patience: ${trainer.patience}
  min_delta: 0.0

checkpoint:
  enabled: true
  monitor: val_f1
  mode: max
  save_top_k: 1
  dirpath: checkpoints
  filename: best-{epoch}-{val_f1:.4f}
  save_last: true