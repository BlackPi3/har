## Manual Trainer configuration for scenario2 (pose2imu + HAR multitask)
defaults:
  - _self_

# todo add weights here later

# Number of epochs/patience used by experiments.run_trial Trainer wrapper
epochs: 100
patience: 25  # early-stopping tolerance (epochs without val improvement)
gradient_clip: 1.0  # set to a positive value (e.g., 1.0) to enable grad clipping

alpha: 1.0  # activity loss weight
beta: 1.0   # feature similarity weight
gamma: 1.0  # regression (MSE) weight
label_smoothing: 0.0  # label smoothing epsilon for activity loss

separate_classifiers: false  # when true, use separate classifier for sim stream
separate_feature_extractors: false  # when true, use a separate feature extractor for sim stream

objective:
  metric: val_f1   # Any key from Trainer history (e.g., val_f1, val_mse, val_loss)
  mode: max        # max to maximize, min to minimize (e.g., use min for val_mse)

# Select which sub-modules receive optimizer updates.
# Modules set to false are frozen (no optimizer params) but still run during forward passes.
trainable_modules:
  pose2imu: true
  fe: true
  ac: true

# Fine-grained loss toggles. Each flag gates the corresponding component regardless of alpha/beta.
losses:
  mse: true
  feature_similarity: true
  activity: true       # Master switch for activity losses
  activity_real: true  # Cross-entropy on real accelerometer branch
  activity_sim: true   # Cross-entropy on simulated accelerometer branch

# Optional secondary pose-only stream (e.g., NTU). Disabled by default.
secondary:
  enabled: false
  loss_weight: 1.0
  data: ntu50.yaml  # name of a config under conf/data (e.g., ntu50.yaml or ntu100.yaml)
  n_classes: 60

# Adversarial training (Scenario 4/42): discriminator with GRL or alternating D/G.
# Scenario 4: feature-level (discriminator.input_type: features) - uses GRL + BCE
# Scenario 42: signal-level (discriminator.input_type: signal) - uses WGAN-GP + alternating
adversarial:
  enabled: false
  weight: 0.1           # weight of adversarial loss in total loss
  use_grl: true         # use Gradient Reversal Layer (recommended for feature-level)
  grl_lambda: 1.0       # GRL strength (fixed or initial value if scheduled)
  schedule_lambda: false  # if true, ramp lambda from 0→1 over training (DANN-style)
  schedule_gamma: 10.0  # steepness of lambda schedule (only used if schedule_lambda=true)
  # Alternating D/G updates (used for signal-level WGAN-GP)
  alternating: false    # set true for WGAN signal-level (auto-enabled if loss_type=wgan & use_grl=false)
  n_critic: 5           # D updates per G update (only for alternating mode)
  # Staged training: pretrain with MSE before adding adversarial loss
  # Literature recommends pretraining on REAL data only before adversarial
  pretrain_epochs: 0    # epochs to train with MSE only (0 = no pretraining)
  discriminator:
    input_type: features  # "features" (Scenario 4) or "signal" (Scenario 42)
    hidden_units: [64]    # MLP hidden layer sizes (for feature discriminator)
    hidden_channels: [32, 64]  # Conv channels (for signal discriminator)
    dropout: 0.3
    normalize_features: true   # L2 normalize features before D (feature discriminator only)
    use_spectral_norm: false   # Constrain D capacity with spectral normalization
    label_smoothing: 0.1       # Smooth labels for BCE (0.1 → real=0.9, fake=0.1)
    # Loss type: "bce" (vanilla GAN) or "wgan" (Wasserstein with gradient penalty)
    # - Feature-level (Scenario 4): BCE + GRL recommended (domain-adversarial approach)
    # - Signal-level (Scenario 42): WGAN-GP + alternating recommended (better time-series gradients)
    loss_type: bce
    lambda_gp: 10.0       # Gradient penalty coefficient (only for WGAN)
    # ACGAN: class-conditional discriminator with auxiliary classifier
    # When enabled, D receives class labels and predicts both real/fake AND activity class
    # Works for BOTH feature-level (ACFeatureDiscriminator) and signal-level (ACSignalDiscriminator)
    # This encourages class-specific realism (e.g., "real jumping" vs "fake jumping")
    use_acgan: false      # Enable ACGAN-style class conditioning
    aux_weight: 1.0       # Weight for auxiliary classification loss
    embed_dim: 32         # Dimension of class label embedding