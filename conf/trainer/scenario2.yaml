## Manual Trainer configuration for scenario2 (pose2imu + HAR multitask)
defaults:
  - _self_

# todo add weights here later

# Number of epochs/patience used by experiments.run_trial Trainer wrapper
epochs: 100
patience: 25  # early-stopping tolerance (epochs without val improvement)
gradient_clip: 1.0  # set to a positive value (e.g., 1.0) to enable grad clipping

alpha: 1.0  # activity loss weight
beta: 1.0   # feature similarity weight
gamma: 1.0  # regression (MSE) weight
label_smoothing: 0.0  # label smoothing epsilon for activity loss

separate_classifiers: false  # when true, use separate classifier for sim stream
separate_feature_extractors: false  # when true, use a separate feature extractor for sim stream

objective:
  metric: val_f1   # Any key from Trainer history (e.g., val_f1, val_mse, val_loss)
  mode: max        # max to maximize, min to minimize (e.g., use min for val_mse)

# Select which sub-modules receive optimizer updates.
# Modules set to false are frozen (no optimizer params) but still run during forward passes.
trainable_modules:
  pose2imu: true
  fe: true
  ac: true

# Fine-grained loss toggles. Each flag gates the corresponding component regardless of alpha/beta.
losses:
  mse: true
  feature_similarity: true
  activity: true       # Master switch for activity losses
  activity_real: true  # Cross-entropy on real accelerometer branch
  activity_sim: true   # Cross-entropy on simulated accelerometer branch

# Optional secondary pose-only stream (e.g., NTU). Disabled by default.
secondary:
  enabled: false
  loss_weight: 1.0
  data: ntu50.yaml  # name of a config under conf/data (e.g., ntu50.yaml or ntu100.yaml)
  n_classes: 60

# Adversarial training (Scenario 4/42): discriminator with GRL.
# Scenario 4: feature-level (discriminator.input_type: features)
# Scenario 42: signal-level (discriminator.input_type: signal)
adversarial:
  enabled: false
  weight: 0.1           # weight of adversarial loss in total loss
  use_grl: true         # use Gradient Reversal Layer (recommended for domain adaptation)
  grl_lambda: 1.0       # GRL strength (fixed or initial value if scheduled)
  schedule_lambda: false  # if true, ramp lambda from 0→1 over training (DANN-style)
  schedule_gamma: 10.0  # steepness of lambda schedule (only used if schedule_lambda=true)
  # For future extension: alternating D/G updates instead of GRL
  alternating: false    # NOT YET IMPLEMENTED - use GRL for now
  n_critic: 1           # D updates per G update (only for alternating mode)
  # Staged training: pretrain regressor with MSE before adding adversarial loss
  # This helps stabilize training by giving the regressor a reasonable starting point
  pretrain_epochs: 0    # epochs to train with MSE only (0 = no pretraining)
  discriminator:
    input_type: features  # "features" (Scenario 4) or "signal" (Scenario 42)
    hidden_units: [64]    # MLP hidden layer sizes (for feature discriminator)
    hidden_channels: [32, 64]  # Conv channels (for signal discriminator)
    dropout: 0.3
    normalize_features: true   # L2 normalize features before D (feature discriminator only)
    use_spectral_norm: false   # Constrain D capacity with spectral normalization
    label_smoothing: 0.1       # Smooth labels for BCE (0.1 → real=0.9, fake=0.1)
    # Loss type: "bce" (vanilla GAN) or "wgan" (Wasserstein with gradient penalty)
    # WGAN recommended for signal-level discrimination (better gradients for time-series)
    # NOTE: For WGAN, set use_grl=false and use alternating optimization (not yet implemented)
    loss_type: bce
    lambda_gp: 10.0       # Gradient penalty coefficient (only for WGAN)