{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from utils import config\n",
    "from utils import utils\n",
    "\n",
    "from utils import mmfit_id_data as mmfit_id\n",
    "from utils.models import Regressor, FeatureExtractor, ActivityClassifier, PersonIdentifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Models <<< #\n",
    "pose2imu_model = Regressor(\n",
    "    in_ch=config.in_ch,\n",
    "    num_joints=config.num_joints,\n",
    "    window_length=config.sensor_window_length\n",
    ").to(config.device)\n",
    "\n",
    "fe_model = FeatureExtractor().to(config.device, non_blocking=True)\n",
    "ac_model = ActivityClassifier(f_in=config.ac_fin, n_classes=config.ac_num_classes).to(config.device, non_blocking=True)\n",
    "pi_model = PersonIdentifier(f_in=config.ac_fin, n_subjects=config.n_subjects).to(config.device, non_blocking=True)\n",
    "\n",
    "# >>> Loss + Optimization <<< #\n",
    "MSELoss = nn.MSELoss()\n",
    "\n",
    "def cosine_similarity_loss(output, target):\n",
    "    cosine_loss = 1 - F.cosine_similarity(output, target, dim=1)\n",
    "    return cosine_loss.mean()\n",
    "\n",
    "CrossEntropyLoss = nn.CrossEntropyLoss()\n",
    "\n",
    "params = (\n",
    "    list(pose2imu_model.parameters())\n",
    "    + list(fe_model.parameters())\n",
    "    + list(ac_model.parameters())\n",
    "    + list(pi_model.parameters())\n",
    ")\n",
    "optimizer = torch.optim.Adam(params, lr=config.lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, alpha: 10, beta: 10, gamma: 10\n",
      "TRAIN Total Loss: 91.3295, MSE Loss: 23.8626, Activity Loss * alpha: 15.5233, ID Loss * beta: 49.4848, Similarity Loss * gamma: 2.4587\n",
      "TRAIN F1: 0.3218, Accuracy: 0.7437\n",
      "VAL Total Loss: 220.4968, MSE Loss: 2.9708, Activity Loss * alpha: 17.8757, ID Loss * beta: 196.2482, Similarity Loss * gamma: 3.4021\n",
      "VAL F1: 0.1474, Accuracy: 0.7101\n",
      "----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# >>> traing model <<< #\n",
    "train_loss_history, train_mse_loss_history, train_similarity_loss_history, train_activity_loss_history, train_id_loss_history, train_f1_history, train_accuracy_history = [], [], [], [], [], [], []\n",
    "val_loss_history, val_mse_loss_history, val_similarity_loss_history, val_activity_loss_history, val_id_loss_history, val_f1_history, val_accuracy_history = [], [], [], [], [], [], []\n",
    "\n",
    "best_pose2imu_model_state, best_fe_model_state, best_ac_model_state, best_pi_model_state = None, None, None, None\n",
    "best_epoch = float('inf')\n",
    "best_val_f1 = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "epochs = config.epochs\n",
    "patience = config.patience\n",
    "epochs_no_improve = 0\n",
    "\n",
    "log = ''\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # - TRAIN\n",
    "    total_train_loss, total_train_mse_loss, total_train_similarity_loss, total_train_activity_loss, total_train_id_loss = 0, 0, 0, 0, 0\n",
    "    all_pred_labels, all_true_labels = [], []  # F1\n",
    "    total_predictions, correct_predictions = 0, 0  # Accuracy\n",
    "\n",
    "    pose2imu_model.train()\n",
    "    fe_model.train()\n",
    "    ac_model.train()\n",
    "    pi_model.train()\n",
    "    for pose, acc, labels, w_id in mmfit_id.train_loader:\n",
    "        \"\"\"\n",
    "        pose: (batch_size, 3, num_joints, sensor_window_length)\n",
    "        acc: (batch_size, 3, sensor_window_length)\n",
    "        \"\"\"\n",
    "        # -- Move to GPU\n",
    "        pose = pose.to(config.device, non_blocking=True)\n",
    "        acc = acc.to(config.device, non_blocking=True)\n",
    "        labels = labels.to(config.device, non_blocking=True)\n",
    "        w_id = w_id.to(config.device, non_blocking=True)\n",
    "\n",
    "        # -- Forward pass\n",
    "        # --- Regressor\n",
    "        sim_acc = pose2imu_model(pose)\n",
    "        mse_loss = MSELoss(sim_acc, acc)  # LOSS\n",
    "        total_train_mse_loss += mse_loss.item()\n",
    "        # --- Feature Extractor\n",
    "        real_acc_features = fe_model(acc)\n",
    "        sim_acc_features = fe_model(sim_acc)\n",
    "        similarity_loss = cosine_similarity_loss(\n",
    "            sim_acc_features, real_acc_features)\n",
    "        total_train_similarity_loss += similarity_loss.item()\n",
    "        # --- Activity Classifier\n",
    "        label_logits = ac_model(real_acc_features)\n",
    "        sim_label_logits = ac_model(sim_acc_features)\n",
    "        activity_loss = CrossEntropyLoss(\n",
    "            label_logits, labels) + CrossEntropyLoss(sim_label_logits, labels)  # LOSS CE\n",
    "        total_train_activity_loss += activity_loss.item()\n",
    "        # --- Person Identifier\n",
    "        id_logits = pi_model(real_acc_features)\n",
    "        sim_id_logits = pi_model(sim_acc_features)\n",
    "        id_loss = CrossEntropyLoss(\n",
    "            id_logits, w_id) + CrossEntropyLoss(sim_id_logits, w_id)  # LOSS CE\n",
    "        total_train_id_loss += id_loss.item()\n",
    "\n",
    "        # --  Total Loss\n",
    "        total_loss = mse_loss + config.scenario3_alpha * activity_loss + \\\n",
    "            config.scenario3_beta * id_loss + config.scenario3_gamma * similarity_loss\n",
    "        total_train_loss += total_loss.item()\n",
    "\n",
    "        # --  F1\n",
    "        pred_labels = torch.argmax(label_logits, dim=1)\n",
    "        all_pred_labels.extend(pred_labels.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # -- Accuracy\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (pred_labels == labels).sum().item()\n",
    "\n",
    "        # -- Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # --  Total Loss\n",
    "    average_train_loss = total_train_loss / len(mmfit_id.train_loader)\n",
    "    train_loss_history.append(average_train_loss)\n",
    "    # --  MSE Loss\n",
    "    average_train_mse_loss = total_train_mse_loss / len(mmfit_id.train_loader)\n",
    "    train_mse_loss_history.append(average_train_mse_loss)\n",
    "    # --  Similarity Loss\n",
    "    average_train_similarity_loss = total_train_similarity_loss / \\\n",
    "        len(mmfit_id.train_loader)\n",
    "    train_similarity_loss_history.append(average_train_similarity_loss)\n",
    "    # --  Activity Loss\n",
    "    average_train_activity_loss = total_train_activity_loss / \\\n",
    "        len(mmfit_id.train_loader)\n",
    "    train_activity_loss_history.append(average_train_activity_loss)\n",
    "    # --  ID Loss\n",
    "    average_train_id_loss = total_train_id_loss / len(mmfit_id.train_loader)\n",
    "    train_id_loss_history.append(average_train_id_loss)\n",
    "\n",
    "    # --  F1\n",
    "    train_f1 = f1_score(all_true_labels, all_pred_labels, average=\"macro\")\n",
    "    train_f1_history.append(train_f1)\n",
    "\n",
    "    # -- Accuracy\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "    # - VAL\n",
    "    total_val_loss, total_val_mse_loss, total_val_similarity_loss, total_val_activity_loss, total_val_id_loss = 0, 0, 0, 0, 0\n",
    "    all_pred_labels, all_true_labels = [], []\n",
    "    total_predictions, correct_predictions = 0, 0\n",
    "\n",
    "    pose2imu_model.eval()\n",
    "    fe_model.eval()\n",
    "    ac_model.eval()\n",
    "    pi_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for pose, acc, labels, w_id in mmfit_id.val_loader:\n",
    "            # -- Move to GPU\n",
    "            pose = pose.to(config.device, non_blocking=True)\n",
    "            acc = acc.to(config.device, non_blocking=True)\n",
    "            labels = labels.to(config.device, non_blocking=True)\n",
    "            w_id = w_id.to(config.device, non_blocking=True)\n",
    "\n",
    "            # -- Forward pass\n",
    "            # --- Regressor\n",
    "            sim_acc = pose2imu_model(pose)\n",
    "            mse_loss = MSELoss(sim_acc, acc)\n",
    "            total_val_mse_loss += mse_loss.item()\n",
    "\n",
    "            # --- Feature Extractor\n",
    "            real_acc_features = fe_model(acc)\n",
    "            sim_acc_features = fe_model(sim_acc)\n",
    "            similarity_loss = cosine_similarity_loss(\n",
    "                sim_acc_features, real_acc_features)\n",
    "            total_val_similarity_loss += similarity_loss.item()\n",
    "            # --- Activity Classifier\n",
    "            label_logits = ac_model(real_acc_features)\n",
    "            sim_label_logits = ac_model(sim_acc_features)\n",
    "            activity_loss = CrossEntropyLoss(\n",
    "                label_logits, labels) + CrossEntropyLoss(sim_label_logits, labels)\n",
    "            total_val_activity_loss += activity_loss.item()\n",
    "            # --- Person Identifier\n",
    "            id_logits = pi_model(real_acc_features)\n",
    "            sim_id_logits = pi_model(sim_acc_features)\n",
    "            id_loss = CrossEntropyLoss(\n",
    "                id_logits, w_id) + CrossEntropyLoss(sim_id_logits, w_id)\n",
    "            total_val_id_loss += id_loss.item()\n",
    "\n",
    "            # -- Total Loss\n",
    "            total_loss = mse_loss + config.scenario3_alpha * activity_loss + \\\n",
    "                config.scenario3_beta * id_loss + config.scenario3_gamma * similarity_loss\n",
    "            total_val_loss += total_loss.item()\n",
    "\n",
    "            # -- F1\n",
    "            pred_labels = torch.argmax(label_logits, dim=1)\n",
    "            all_pred_labels.extend(pred_labels.cpu().numpy())\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # -- Accuracy\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (pred_labels == labels).sum().item()\n",
    "\n",
    "    # -- Total Loss\n",
    "    average_val_loss = total_val_loss / len(mmfit_id.val_loader)\n",
    "    val_loss_history.append(average_val_loss)\n",
    "    # -- MSE Loss\n",
    "    average_val_mse_loss = total_val_mse_loss / len(mmfit_id.val_loader)\n",
    "    val_mse_loss_history.append(average_val_mse_loss)\n",
    "    # -- Similarity Loss\n",
    "    average_val_similarity_loss = total_val_similarity_loss / \\\n",
    "        len(mmfit_id.val_loader)\n",
    "    val_similarity_loss_history.append(average_val_similarity_loss)\n",
    "    # -- Activity Loss\n",
    "    average_val_activity_loss = total_val_activity_loss / \\\n",
    "        len(mmfit_id.val_loader)\n",
    "    val_activity_loss_history.append(average_val_activity_loss)\n",
    "    # -- ID Loss\n",
    "    average_val_id_loss = total_val_id_loss / len(mmfit_id.val_loader)\n",
    "    val_id_loss_history.append(average_val_id_loss)\n",
    "\n",
    "    # -- F1\n",
    "    val_f1 = f1_score(all_true_labels, all_pred_labels, average=\"macro\")\n",
    "    val_f1_history.append(val_f1)\n",
    "\n",
    "    # -- Accuracy\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "    val_accuracy_history.append(val_accuracy)\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "    out = (f\"Epoch {epoch+1}/{epochs}, alpha: {config.scenario3_alpha}, beta: {config.scenario3_beta}, gamma: {config.scenario3_gamma}\" +\n",
    "           f\"\\nTRAIN Total Loss: {average_train_loss:.4f}, MSE Loss: {average_train_mse_loss:.4f}, Activity Loss * alpha: {average_train_activity_loss * config.scenario3_alpha:.4f}, ID Loss * beta: {average_train_id_loss * config.scenario3_beta:.4f}, Similarity Loss * gamma: {average_train_similarity_loss * config.scenario3_gamma:.4f}\" +\n",
    "           f'\\nTRAIN F1: {train_f1:.4f}, Accuracy: {train_accuracy:.4f}' +\n",
    "           f'\\nVAL Total Loss: {average_val_loss:.4f}, MSE Loss: {average_val_mse_loss:.4f}, Activity Loss * alpha: {average_val_activity_loss * config.scenario3_alpha:.4f}, ID Loss * beta: {average_val_id_loss * config.scenario3_beta:.4f}, Similarity Loss * gamma: {average_val_similarity_loss * config.scenario3_gamma:.4f}' +\n",
    "           f'\\nVAL F1: {val_f1:.4f}, Accuracy: {val_accuracy:.4f}' +\n",
    "           f'\\n----------------------------------------------------\\n')\n",
    "\n",
    "    print(out)\n",
    "\n",
    "    if best_val_f1 < val_f1:\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        best_val_f1 = val_f1\n",
    "        best_val_acc = val_accuracy\n",
    "        best_epoch = epoch\n",
    "\n",
    "        best_pose2imu_model_state = copy.deepcopy(pose2imu_model.state_dict())\n",
    "        best_fe_model_state = copy.deepcopy(fe_model.state_dict())\n",
    "        best_ac_model_state = copy.deepcopy(ac_model.state_dict())\n",
    "\n",
    "        log = out\n",
    "\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve == patience:\n",
    "        pose2imu_model.load_state_dict(best_pose2imu_model_state)\n",
    "        fe_model.load_state_dict(best_fe_model_state)\n",
    "        ac_model.load_state_dict(best_ac_model_state)\n",
    "\n",
    "        break\n",
    "\n",
    "    scheduler.step(average_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Test <<< #\n",
    "# - Test\n",
    "total_loss = 0\n",
    "all_pred_labels, all_true_labels = [], []\n",
    "total_predictions, correct_predictions = 0, 0\n",
    "\n",
    "fe_model.eval()\n",
    "ac_model.eval()\n",
    "with torch.no_grad():\n",
    "    for pose, acc, labels, w_id in mmfit_id.test_loader:\n",
    "        # -- Move to GPU\n",
    "        acc = acc.to(config.device, non_blocking=True)\n",
    "        labels = labels.to(config.device, non_blocking=True)\n",
    "\n",
    "        # -- Forward pass\n",
    "        # --- Feature Extractor\n",
    "        real_acc_features = fe_model(acc)\n",
    "        # --- Activity Classifier\n",
    "        label_logits = ac_model(real_acc_features)\n",
    "\n",
    "        # -- F1\n",
    "        pred_labels = torch.argmax(label_logits, dim=1)\n",
    "        all_pred_labels.extend(pred_labels.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # -- Accuracy\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (pred_labels == labels).sum().item()\n",
    "\n",
    "    # -- F1\n",
    "    f1 = f1_score(all_true_labels, all_pred_labels, average=\"macro\")\n",
    "\n",
    "    # -- Accuracy\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    log += f\"Test F1: {f1:.4f}, Test Accuracy: {accuracy:.4f}\" + \\\n",
    "            f'\\n----------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Save models and metrics <<< #\n",
    "\n",
    "prefix = config.scenario3_name + \"[s=\" + str(utils.args.seed) + \"]\" + '[a=' + str(config.scenario3_alpha) + ']' + '[b=' + str(config.scenario3_beta) + ']' + '[g=' + str(config.scenario3_gamma) + ']'\n",
    "metric_suffix = '[MSE+Similarity+Activity+ID]' if config.scenario3_gamma != 0 else '[MSE+Activity+ID]'\n",
    "\n",
    "# SAVE models to file\n",
    "# name = 'allacc2activity-ae(model)'\n",
    "# save_model(acc_ae, name)\n",
    "\n",
    "# name = 'allacc2activity-fc(model)'\n",
    "# save_model(classifier, name)\n",
    "\n",
    "# Total Loss Plot\n",
    "metric = 'Total Loss' + metric_suffix\n",
    "file_name = '1_' + prefix + '(' + metric + ')'\n",
    "utils.save_plot(\n",
    "    epochs=epoch,\n",
    "    best_epoch=best_epoch,\n",
    "    train_metric_history=train_loss_history,\n",
    "    val_metric_history=val_loss_history,\n",
    "    metric=metric,\n",
    "    file_name=file_name,\n",
    ")\n",
    "# Save MSE Loss plot\n",
    "metric = 'MSE Loss'\n",
    "file_name = '2_' + prefix + '(' + metric + ')'\n",
    "utils.save_plot(\n",
    "    epochs=epoch,\n",
    "    best_epoch=best_epoch,\n",
    "    train_metric_history=train_mse_loss_history,\n",
    "    val_metric_history=val_mse_loss_history,\n",
    "    metric=metric,\n",
    "    file_name=file_name,\n",
    ")\n",
    "# Save Similarity Loss plot\n",
    "metric = 'Similarity Loss'\n",
    "file_name = '3_' + prefix + '(' + metric + ')'\n",
    "utils.save_plot(\n",
    "    epochs=epoch,\n",
    "    best_epoch=best_epoch,\n",
    "    train_metric_history=train_similarity_loss_history,\n",
    "    val_metric_history=val_similarity_loss_history,\n",
    "    metric=metric,\n",
    "    file_name=file_name,\n",
    ")\n",
    "# Save Activity Loss plot\n",
    "metric = 'Activity Loss'\n",
    "file_name = '4_' + prefix + '(' + metric + ')'\n",
    "utils.save_plot(\n",
    "    epochs=epoch,\n",
    "    best_epoch=best_epoch,\n",
    "    train_metric_history=train_activity_loss_history,\n",
    "    val_metric_history=val_activity_loss_history,\n",
    "    metric=metric,\n",
    "    file_name=file_name,\n",
    ")\n",
    "# Save ID Loss plot\n",
    "metric = 'ID Loss'\n",
    "file_name = '5_' + prefix + '(' + metric + ')'\n",
    "utils.save_plot(\n",
    "    epochs=epoch,\n",
    "    best_epoch=best_epoch,\n",
    "    train_metric_history=train_id_loss_history,\n",
    "    val_metric_history=val_id_loss_history,\n",
    "    metric=metric,\n",
    "    file_name=file_name,\n",
    ")\n",
    "\n",
    "# Save F1 score plot\n",
    "metric = 'F1'\n",
    "file_name = '6_' + prefix + '(' + metric + ')'\n",
    "utils.save_plot(\n",
    "    epochs=epoch,\n",
    "    best_epoch=best_epoch,\n",
    "    train_metric_history=train_f1_history,\n",
    "    val_metric_history=val_f1_history,\n",
    "    metric=metric,\n",
    "    file_name=file_name,\n",
    ")\n",
    "\n",
    "# Save Accuracy\n",
    "metric = 'Accuracy'\n",
    "file_name = '7_' + prefix + '(' + metric + ')'\n",
    "utils.save_plot(\n",
    "    epochs=epoch,\n",
    "    best_epoch=best_epoch,\n",
    "    train_metric_history=train_accuracy_history,\n",
    "    val_metric_history=val_accuracy_history,\n",
    "    metric=metric,\n",
    "    file_name=file_name,\n",
    ")\n",
    "\n",
    "# Save log\n",
    "log += prefix + '\\n' + metric_suffix\n",
    "file_name = '8_' + prefix + '(Log)'\n",
    "utils.save_log(log=log, file_name=file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
