\chapter{Method}
\label{chap:method}

This section describes our method to enhance HAR which focuses on the efficient use of available real and simulated sensor data.
While most other methods consider sensor data simulation and training a HAR classifier as different, independent steps, ours performs both in an end-to-end fashion.

\section{Problem Formulation}
\label{sec:problem}

We address the challenge of improving HAR by leveraging simulated IMU data derived from skeletal pose sequences. This section formally defines the problem and our approach.

\subsection{Task Definition}

Let $\mathcal{D}_{\text{real}} = \{(\mathbf{p}_i, \mathbf{a}_i, y_i)\}_{i=1}^{N}$ denote a dataset where each sample consists of:
\begin{itemize}
    \item $\mathbf{p}_i \in \mathbb{R}^{T \times J \times 3}$: a pose sequence of $T$ timesteps with $J$ skeletal joints in 3D space
    \item $\mathbf{a}_i \in \mathbb{R}^{T \times 3}$: corresponding real accelerometer signal (3-axis)
    \item $y_i \in \{1, \ldots, K\}$: activity class label from $K$ possible activities
    \item $\mathbf{p}_i$ and $\mathbf{a}_i$ are synchronized unless explicitly stated
\end{itemize}

The core task comprises two coupled sub-problems:

\textbf{Pose-to-IMU Regression.} Learn a mapping $R: \mathbb{R}^{T \times J \times 3} \rightarrow \mathbb{R}^{T \times 3}$ that transforms skeleton pose sequences into simulated accelerometer signals:
\begin{equation}
    \tilde{\mathbf{a}} = R(\mathbf{p})
\end{equation}
where $\tilde{\mathbf{a}}$ approximates the characteristics of real accelerometer data $\mathbf{a}$.

\textbf{Activity Classification.} Learn a classifier $C \circ F: \mathbb{R}^{T \times 3} \rightarrow \mathbb{R}^{K}$ composed of a feature extractor $F$ and classification head $C$, such that for a real accelerometer input $\mathbf{a}$:
\begin{equation}
    \hat{y} = \arg\max_k \, [C(F(\mathbf{a}))]_k
\end{equation}

We assume that pose sequences $\mathbf{p}$ and accelerometer signals $\mathbf{a}$ are temporally synchronized and correspond to the same activity instance.

\subsection{Joint Training Objective}

Rather than treating pose-to-IMU regression and HAR as independent tasks, we use an end-to-end framework optimizes both simultaneously \cite{zolfaghari2024sensor}. The key insight is that the regressor $R$, feature extractor $F$, and classifier $C$ can mutually benefit from joint training:

\begin{enumerate}
    \item The classifier provides supervision that guides the regressor to produce activity-discriminative simulated signals
    \item The simulated data augments training, exposing the feature extractor to greater variation
    \item Feature-level losses encourage domain alignment between real and simulated representations
\end{enumerate}

The general training objective takes the form:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}} + \mathcal{L}_{\text{auxiliary}}
\end{equation}
where $\alpha$, $\beta$, $\gamma$ are loss weights controlling the contribution of classification, consistency, and regression objectives respectively, and $\mathcal{L}_{\text{auxiliary}}$ encompasses additional terms such as adversarial or secondary dataset losses depending on the training scenario.

\subsection{Evaluation Protocol}

Critically, at inference time only the real accelerometer branch is used:
\begin{equation}
    \hat{y} = \arg\max_k \, [C(F(\mathbf{a}_{\text{real}}))]_k
\end{equation}
The simulated data path ($R$, and optionally separate $F_{\text{sim}}$, $C_{\text{sim}}$) serves purely as a training-time augmentation mechanism. This ensures that evaluation metrics reflect real-world deployment performance where only physical sensor data is available.

\section{System Architecture}
\label{sec:architecture}

Our framework employs a two-stream architecture that processes both real and simulated accelerometer data during training. This section describes the baseline configuration, which serves as the foundation for all experimental variants explored in this work.

All real accelerometer signals $\mathbf{a}$ and pose sequences $\mathbf{p}$ undergo preprocessing (normalization and standardization) as described in \Cref{chap:implementation}.  
Simulated accelerometer signals $\tilde{\mathbf{a}}$ are generated by the regressor $R$ in this normalized space and are not subject to additional preprocessing.

\subsection{Two-Stream Design}

The architecture comprises three core components that operate on parallel data streams during training:

\begin{enumerate}
    \item \textbf{Pose-to-IMU Regressor} ($R$): Transforms skeleton pose sequences into simulated accelerometer signals
    \item \textbf{Feature Extractor} ($F$): Encodes accelerometer signals (real or simulated) into fixed-dimensional feature representations
    \item \textbf{Activity Classifier} ($C$): Maps feature representations to activity class predictions
\end{enumerate}

\Cref{fig:baseline} illustrates the baseline architecture. During each training iteration, a batch contains synchronized triplets $(\mathbf{p}, \mathbf{a}, y)$ of pose sequences, real accelerometer data, and activity labels. The data flows through two parallel paths:

\textbf{Real Path:}
\begin{equation}
    \mathbf{a} \xrightarrow{F} \mathbf{z}_{\text{real}} \xrightarrow{C} \hat{y}_{\text{real}}
\end{equation}

\textbf{Simulated Path:}
\begin{equation}
    \mathbf{p} \xrightarrow{R} \tilde{\mathbf{a}} \xrightarrow{F} \mathbf{z}_{\text{sim}} \xrightarrow{C} \hat{y}_{\text{sim}}
\end{equation}

where $\mathbf{z}_{\text{real}}, \mathbf{z}_{\text{sim}} \in \mathbb{R}^{d}$ are the $d$-dimensional feature embeddings extracted by $F$.

In the baseline configuration, both paths share the same feature extractor $F$ and classifier $C$. This weight sharing encourages the network to learn domain-invariant representations that perform well regardless of whether the input is real or simulated accelerometer data.

\subsection{Component Interactions}

The three components interact through multiple loss signals that provide complementary supervision:

\begin{itemize}
    \item The \textbf{regressor} $R$ receives gradients from the regression loss (comparing $\tilde{\mathbf{a}}$ to $\mathbf{a}$) and, through backpropagation, from downstream classification losses
    \item The \textbf{feature extractor} $F$ receives gradients from both classification paths and optionally from a feature similarity loss that encourages $\mathbf{z}_{\text{real}} \approx \mathbf{z}_{\text{sim}}$
    \item The \textbf{classifier} $C$ receives supervision from activity labels on both real and simulated features
\end{itemize}

This joint optimization allows each component to benefit from the others: the regressor learns to produce signals that are not only similar to real data but also activity-discriminative, while the feature extractor learns representations robust to the domain gap between real and simulated inputs.

\section{Loss Function Design}
\label{sec:losses}

The training objective combines multiple loss terms that guide different aspects of learning. Each loss component addresses a specific goal, and their relative importance is controlled by three weighting coefficients: $\alpha$, $\beta$, and $\gamma$.

\subsection{Classification Loss}

The primary objective is accurate activity recognition. We apply cross-entropy loss on both the real and simulated accelerometer paths:
\begin{equation}
    \mathcal{L}_{\text{cls}} = -\sum_{i=1}^{N} \sum_{k=1}^{K} w_k \, y_{i,k} \left( \log \hat{y}_{i,k}^{\text{real}} + \log \hat{y}_{i,k}^{\text{sim}} \right)
\end{equation}
where $y_{i,k}$ is the one-hot encoded ground truth, $\hat{y}_{i,k}^{\text{real}} = [C(F(\mathbf{a}_i))]_k$ and $\hat{y}_{i,k}^{\text{sim}} = [C(F(\tilde{\mathbf{a}}_i))]_k$ are the predicted probabilities from the real and simulated paths respectively, and $w_k$ are optional class weights to handle imbalanced datasets. By training on both paths with the same labels, the classifier learns to produce correct predictions regardless of whether the input originates from real or simulated accelerometer data. This loss is weighted by coefficient $\alpha$.

\subsection{Feature Similarity Loss}

To encourage domain-invariant representations, we minimize the distance between feature embeddings of real and simulated data using cosine similarity:
\begin{equation}
    \mathcal{L}_{\text{similarity}} = 1 - \frac{1}{N} \sum_{i=1}^{N} \cos(\mathbf{z}_{\text{real},i}, \mathbf{z}_{\text{sim},i})
\end{equation}
where $\cos(\cdot, \cdot)$ denotes cosine similarity. This loss operates at the feature level, pushing the feature extractor to produce similar representations for corresponding real and simulated samples. This loss is weighted by coefficient $\beta$.

\subsection{Regression Loss}

To guide the regressor toward producing realistic accelerometer signals, we minimize the mean squared error between simulated and real data:
\begin{equation}
    \mathcal{L}_{\text{regression}} = \frac{1}{N} \sum_{i=1}^{N} \lVert \mathbf{a}_i - \tilde{\mathbf{a}}_i \rVert^{2}
\end{equation}
This signal-level supervision ensures the regressor learns the mapping from pose to accelerometer in a physically meaningful way. The regression loss is weighted by coefficient $\gamma$.

\subsection{Total Objective}

The baseline training objective combines these three losses:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}}
    \label{eq:total_loss}
\end{equation}
where $\alpha$, $\beta$, and $\gamma$ are hyperparameters controlling the contribution of each term. Different experimental configurations selectively enable or disable these terms to study their individual contributions, as detailed in \Cref{sec:scenarios}.

All loss weights ($\alpha, \beta, \gamma, \lambda_{\text{aux}}, \lambda_{\text{adv}}$) and optimization details are specified in \Cref{chap:implementation}.

\section{Training Scenarios}
\label{sec:scenarios}

To systematically investigate the contributions of different architectural choices and loss components, we define eight training scenarios. Each scenario modifies the baseline configuration in a specific way, enabling controlled ablation studies and architectural comparisons.

\Cref{tab:scenarios} summarizes all scenarios. The following subsections describe each variant in detail.

\begin{table}[!t]
\centering
\caption{Overview of training scenarios. Each row indicates which components are modified relative to the baseline.}
\label{tab:scenarios}
\begin{tabular}{lp{6cm}}
\hline
\textbf{Scenario} & \textbf{Description} \\
\hline
Baseline & Shared $F$ and $C$; all losses enabled ($\alpha, \beta, \gamma > 0$) \\
Ablation: MSE & Baseline with $\gamma = 0$ (no regression loss) \\
Ablation: Similarity & Baseline with $\beta = 0$ (no feature similarity loss) \\
Shared rep. \& Sep. Cls. & Separate classifiers $C$ and $C_{\text{sim}}$ for real and simulated paths \\
Sep. rep. \& Shared Cls. & Separate feature extractors $F$ and $F_{\text{sim}}$ for real and simulated paths \\
Auxiliary Pose & Additional pose-only dataset (NTU) with secondary classifier \\
Feature Discriminator & Adversarial discriminator on feature embeddings \\
Signal Discriminator & Adversarial discriminator on raw accelerometer signals \\
\hline
\end{tabular}
\end{table}

\subsection{Baseline}
\label{sec:scenario-baseline}

The baseline configuration uses shared weights for both the feature extractor and classifier across real and simulated paths. All three loss terms are active: classification ($\alpha > 0$), feature similarity ($\beta > 0$), and regression ($\gamma > 0$). This represents the simplest form of joint training where the network must learn domain-invariant representations through weight sharing alone.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-baseline.pdf}
  \caption{Baseline architecture with shared feature extractor $F$ and classifier $C$. Real accelerometer data $\mathbf{a}$ and simulated data $\tilde{\mathbf{a}}$ (from regressor $R$) pass through the same network. Three losses guide training: classification loss $\mathcal{L}_{\text{cls}}$ (weighted by $\alpha$), feature similarity loss $\mathcal{L}_{\text{sim}}$ (weighted by $\beta$), and regression loss $\mathcal{L}_{\text{reg}}$ (weighted by $\gamma$).}
  \label{fig:baseline}
\end{figure}

\subsection{Ablation: Effect of MSE Loss}
\label{sec:scenario-mse-ablation}

This ablation sets $\gamma = 0$, removing the regression loss entirely. The regressor still produces simulated accelerometer signals, but receives no direct signal-level supervision. Instead, it relies solely on gradients backpropagated from the classification and similarity losses. This tests whether explicit signal matching is necessary, or whether task-driven gradients suffice.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-gamma.pdf}
  \caption{Ablation: removing the regression loss ($\gamma = 0$). The regressor $R$ receives no direct signal-level supervision; gradients flow only through the classification and similarity losses. This tests whether task-driven gradients alone can guide meaningful pose-to-IMU simulation.}
  \label{fig:ablation-mse}
\end{figure}

\subsection{Ablation: Effect of Similarity Loss}
\label{sec:scenario-sim-ablation}

This ablation sets $\beta = 0$, removing the feature similarity loss. The feature extractor no longer receives explicit pressure to align real and simulated representations. This tests whether the shared architecture alone provides sufficient domain alignment, or whether explicit feature matching is beneficial.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-beta.pdf}
  \caption{Ablation: removing the feature similarity loss ($\beta = 0$). The feature extractor $F$ no longer receives explicit pressure to align $\mathbf{z}_{\text{real}}$ and $\mathbf{z}_{\text{sim}}$. Domain alignment relies solely on the shared architecture.}
  \label{fig:ablation-sim}
\end{figure}

\subsection{Shared Representation, Separate Classifiers}
\label{sec:scenario-dual-classifier}

This variant introduces a second classifier $C_{\text{sim}}$ dedicated to the simulated path:
\begin{equation}
    \hat{y}_{\text{sim}} = C_{\text{sim}}(F(\tilde{\mathbf{a}}))
\end{equation}
while the real path continues to use the original classifier $C$. Both classifiers share the same feature extractor $F$. The motivation is that simulated and real features, while similar, may benefit from specialized decision boundaries. At inference time, only $C$ is used with real accelerometer data.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-sharedrep.pdf}
  \caption{Shared representation, separate classifiers. Both paths share the feature extractor $F$, but use separate classifiers: $C$ for real features and $C_{\text{sim}}$ for simulated features. This allows domain-specific decision boundaries while maintaining shared feature representations. At inference, only $C$ is used.}
  \label{fig:dual-classifier}
\end{figure}

\subsection{Separate Representations, Shared Classifier}
\label{sec:scenario-dual-encoder}

This variant introduces a second feature extractor $F_{\text{sim}}$ dedicated to the simulated path:
\begin{equation}
    \mathbf{z}_{\text{sim}} = F_{\text{sim}}(\tilde{\mathbf{a}})
\end{equation}
while the real path uses the original $F$. Both feature extractors feed into the same classifier $C$. The motivation is that real and simulated accelerometer signals may have different characteristics requiring specialized encoding, while the classification task remains unified. At inference time, only $F$ is used.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-sharedcls.pdf}
  \caption{Separate representations, shared classifier. The real path uses feature extractor $F$ while the simulated path uses $F_{\text{sim}}$, allowing domain-specific encoding. Both feed into the same classifier $C$. At inference, only $F$ is used.}
  \label{fig:dual-encoder}
\end{figure}

\subsection{Auxiliary Pose Data}
\label{sec:scenario-auxiliary}

Compared to the baseline, this scenario introduces an additional pose-only dataset and a secondary classifier, while keeping the main real/sim architecture unchanged.

This scenario augments training with a secondary pose-only dataset (NTU RGB+D) that lacks corresponding real accelerometer data. Although NTU RGB+D contains different activity classes than the primary dataset, we select the same subset of skeletal joints across both datasets to ensure the regressor $R$ receives consistently structured pose inputs. The secondary data flows through the regressor and feature extractor, then to a dedicated secondary classifier $C_{\text{aux}}$:
\begin{equation}
    \mathbf{p}_{\text{aux}} \xrightarrow{R} \tilde{\mathbf{a}}_{\text{aux}} \xrightarrow{F_{\text{sim}}} \mathbf{z}_{\text{aux}} \xrightarrow{C_{\text{aux}}} \hat{y}_{\text{aux}}
\end{equation}
The secondary classification loss is weighted by a separate coefficient $\lambda_{\text{aux}}$:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}} + \lambda_{\text{aux}} \mathcal{L}_{\text{aux}}
\end{equation}
This tests whether additional pose diversity improves the regressor's generalization, even when the auxiliary dataset has different activity classes. 

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-aux.pdf}
  \caption{Auxiliary pose data scenario. A secondary pose-only dataset (NTU RGB+D) augments training. Secondary poses flow through the regressor $R$ and feature extractor $F_{\text{sim}}$ to a dedicated classifier $C_{\text{aux}}$. The auxiliary loss $\mathcal{L}_{\text{aux}}$ (weighted by $\lambda_{\text{aux}}$) provides additional supervision to improve regressor generalization.}
  \label{fig:auxiliary-pose}
\end{figure}

\subsection{Feature-level Discriminator}
\label{sec:scenario-disc-feature}

This scenario extends the baseline by adding an adversarial discriminator on feature embeddings. Additionally, this scenario employs separate feature extractors ($F$ for real, $F_{\text{sim}}$ for simulated) and separate classifiers ($C$ for real, $C_{\text{sim}}$ for simulated) to allow each path to specialize while the discriminator enforces domain alignment at the feature level.

The discriminator $D$ operates on feature embeddings and attempts to distinguish real features $\mathbf{z}_{\text{real}}$ from simulated features $\mathbf{z}_{\text{sim}}$:
\begin{equation}
    D: \mathbb{R}^d \rightarrow [0, 1]
\end{equation}
where output near 1 indicates ``real'' and near 0 indicates ``simulated.''

A Gradient Reversal Layer (GRL) enables end-to-end training: during the forward pass, GRL acts as identity; during backpropagation, it negates gradients by a factor $\lambda_{\text{adv}}$. This creates an adversarial signal that pushes the feature extractor to produce domain-invariant features that fool the discriminator.

The adversarial loss follows the standard binary cross-entropy formulation:
\begin{equation}
    \mathcal{L}_{\text{adv}} = -\mathbb{E}[\log D(\mathbf{z}_{\text{real}})] - \mathbb{E}[\log(1 - D(\mathbf{z}_{\text{sim}}))]
\end{equation}
The discriminator $D$ is trained to minimize this loss (correctly classifying domains), while the GRL causes the feature extractor to maximize it (producing indistinguishable features). The total training objective becomes:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}} - \lambda_{\text{adv}} \mathcal{L}_{\text{adv}}
\end{equation}
where the negative sign reflects the adversarial nature: the main network minimizes $\mathcal{L}_{\text{total}}$ while effectively maximizing $\mathcal{L}_{\text{adv}}$ through the GRL.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-featdisc.pdf}
  \caption{Feature-level discriminator with Gradient Reversal Layer (GRL). The discriminator $D$ classifies features as real or simulated. During backpropagation, the GRL negates gradients (multiplies by $-\lambda$), creating an adversarial signal that encourages $F$ to produce domain-invariant features that fool $D$.}
  \label{fig:disc-feature}
\end{figure}

\subsection{Signal-level Discriminator}
\label{sec:scenario-disc-signal}

In contrast to feature-level discrimination, this variant applies adversarial supervision directly at the signal level, primarily affecting the regressor. Like the feature-level variant, this scenario also employs separate feature extractors ($F$ for real, $F_{\text{sim}}$ for simulated) and separate classifiers ($C$ for real, $C_{\text{sim}}$ for simulated).

The discriminator operates on raw accelerometer signals rather than features:
\begin{equation}
    D: \mathbb{R}^{T \times 3} \rightarrow [0, 1]
\end{equation}
The discriminator distinguishes real accelerometer data $\mathbf{a}$ from simulated data $\tilde{\mathbf{a}}$ produced by the regressor. This directly pressures the regressor to produce realistic-looking signals, complementing the MSE loss.

The adversarial loss mirrors the feature-level formulation:
\begin{equation}
    \mathcal{L}_{\text{adv}} = -\mathbb{E}[\log D(\mathbf{a})] - \mathbb{E}[\log(1 - D(\tilde{\mathbf{a}}))]
\end{equation}
and the total objective follows the same structure:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}} - \lambda_{\text{adv}} \mathcal{L}_{\text{adv}}
\end{equation}

The key difference from feature-level discrimination is where the adversarial gradient flows: here it primarily affects the regressor $R$, encouraging it to generate signals indistinguishable from real sensor data, while feature-level discrimination primarily affects the feature extractor $F$.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-signaldisc.pdf}
  \caption{Signal-level discriminator. Unlike feature-level discrimination, $D$ operates on raw accelerometer signals $\mathbf{a}$ vs.\ $\tilde{\mathbf{a}}$. The GRL reverses gradients to the regressor $R$, directly pressuring it to produce realistic accelerometer waveforms indistinguishable from real sensor data.}
  \label{fig:disc-signal}
\end{figure}