\chapter{Method}
\label{chap:method}

This chapter describes our method to enhance HAR which focuses on the efficient use of available real and simulated sensor data.
While most other methods consider sensor data simulation and training a HAR classifier as different, independent steps, ours performs both in an end-to-end fashion.

\section{Problem Formulation}
\label{sec:problem}

We address the challenge of improving HAR by leveraging simulated IMU data derived from skeletal pose sequences. This section first describes how the input data is acquired, then formally defines the problem and our approach.

\subsection{Data Acquisition}
\label{sec:data-acquisition}

In this thesis we require synchronized pairs of skeletal pose sequences and accelerometer signals that are labeled with activity classes. These data streams originate from different sensor modalities and undergo preprocessing before use.

\textbf{Accelerometer Data} is a component of Inertial Measurement Units (IMUs) embedded in smartphones, smartwatches, or dedicated wearable devices capture tri-axial acceleration at fixed sampling rates (typically 50--100\,Hz). 

\textbf{Pose Sequences} is extracted from visual sensors, RGB cameras, depth sensors (RGB-D), or multi-view camera arrays (Fig. \ref{fig:3dpose-extraction}). Vision-based pose estimation pipelines first detect 2D keypoints in each frame using convolutional detectors, then lift these to 3D joint coordinates through volumetric representations, using various methods such as triangulation from multiple views, or learned regressors.

\textbf{Synchronization} of multi-sensor recordings require temporal alignment so that each pose frame corresponds to the concurrent accelerometer sample. Datasets such as MM-Fit provide time-synchronized streams, enabling direct pairing of pose and accelerometer windows for the same activity instance \cite{stromback2020mm}. This synchronization is essential for learning the pose-to-accelerometer mapping, as the regressor must observe corresponding motion patterns in both modalities.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/3d-pose-extraction.pdf}
  \caption{Steps in which 3D pose sequence is extracted from frames}
  \label{fig:3dpose-extraction}
\end{figure}

\subsection{Task Definition}

Let $\mathcal{D} = \{(\mathbf{p}_i, \mathbf{a}_i, y_i)\}_{i=1}^{N}$ denote a dataset of synchronized triplets:
\begin{itemize}
    \item $\mathbf{p}_i \in \mathbb{R}^{T \times J \times 3}$: a pose sequence of $T$ timesteps with $J$ skeletal joints in 3D space
    \item $\mathbf{a}_i \in \mathbb{R}^{T \times 3}$: corresponding real accelerometer signal (3-axis)
    \item $y_i \in \{1, \ldots, K\}$: activity class label from $K$ possible activities
\end{itemize}

Our task is to use the pose data $\mathbf{p}$ to generate synthetic accelerometer signals $\tilde{\mathbf{a}}$. Since each pose sequence $\mathbf{p}_i$ is synchronized with its corresponding real accelerometer $\mathbf{a}_i$, they share the same activity label $y_i$. Therefore, the synthetic signal $\tilde{\mathbf{a}}_i$ also inherits this label, effectively augmenting the training set with additional labeled samples. This augmented data can then be used to train a more robust activity classifier.

To achieve this, we define three learned components:

\textbf{Pose-to-IMU Regressor.} A mapping $R: \mathbb{R}^{T \times J \times 3} \rightarrow \mathbb{R}^{T \times 3}$ that transforms pose sequences into simulated accelerometer signals:
\begin{equation}
    \tilde{\mathbf{a}} = R(\mathbf{p})
    \label{eq:R}
\end{equation}

\textbf{Feature Extractor.} A mapping $F: \mathbb{R}^{T \times 3} \rightarrow \mathbb{R}^{d}$ that encodes accelerometer signals into $d$-dimensional feature embeddings:
\begin{equation}
    \mathbf{z} = F(\mathbf{a})
\end{equation}

\textbf{Activity Classifier.} A mapping $C: \mathbb{R}^{d} \rightarrow \mathbb{R}^{K}$ that predicts activity classes from feature representations:
\begin{equation}
    \hat{y} = \arg\max_k \, [C(\mathbf{z})]
    \label{eq:C}
\end{equation}

\subsection{Scenario 1: Two-Step Training}
\label{sec:two-step}

The most intuitive way to use simulated data for HAR is a two-step process:

\textbf{Step 1: Train the Regressor.} First, train $R$ to produce realistic simulated accelerometer signals by minimizing the reconstruction error between $\tilde{\mathbf{a}}$ and $\mathbf{a}$:
\begin{equation}
    \mathcal{L}_{\text{regression}} = \frac{1}{N} \sum_{i=1}^{N} \lVert \mathbf{a}_i - R(\mathbf{p}_i) \rVert^{2}
\end{equation}
Once trained, the regressor can generate synthetic accelerometer data $\tilde{\mathbf{a}}_i$ for any pose sequence $\mathbf{p}_i$.

\textbf{Step 2: Train HAR with Augmented Data.} Freeze $R$ and use it to generate synthetic accelerometer signals. Then train $F$ and $C$ on both real and simulated data:
\begin{equation}
    \mathbf{z}_{\text{real}} = F(\mathbf{a}), \quad \mathbf{z}_{\text{sim}} = F(\tilde{\mathbf{a}})
    \label{eq:F}
\end{equation}
\begin{equation}
    \hat{y}_{\text{real}} = \arg\max_k [C(\mathbf{z}_{\text{real}})], \quad \hat{y}_{\text{sim}} = \arg\max_k [C(\mathbf{z}_{\text{sim}})]
\end{equation}
Since both $\mathbf{a}$ and $\tilde{\mathbf{a}}$ share the same label $y$, the classifier effectively trains on an augmented dataset. The training objective in this step combines a classification loss on both paths and optionally a feature similarity loss to encourage domain alignment:
\begin{equation}
    \mathcal{L}_{\text{similarity}} = 1 - \cos(\mathbf{z}_{\text{real}}, \mathbf{z}_{\text{sim}})
\end{equation}
\begin{equation}
    \mathcal{L}_{\text{cls}} = \text{CE}(\hat{y}_{\text{real}}, y) + \text{CE}(\hat{y}_{\text{sim}}, y)
\end{equation}
where CE denotes cross-entropy loss and $\cos(\cdot, \cdot)$ denotes cosine similarity. The similarity loss encourages $F$ to produce similar representations for corresponding real and simulated samples, reducing the domain gap.

This sequential approach treats pose-to-IMU regression and activity classification as independent tasks and we refer to it as \textbf{Scenario 1}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.85\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-baseline.pdf}
  \caption{Baseline architecture (Scenario 2.1) with shared feature extractor $F$ and classifier $C$. Real accelerometer data $\mathbf{a}$ and simulated data $\tilde{\mathbf{a}}$ (from regressor $R$) pass through the same network. Three losses guide training: classification loss $\mathcal{L}_{\text{cls}}$ (weighted by $\alpha$), feature similarity loss $\mathcal{L}_{\text{sim}}$ (weighted by $\beta$), and regression loss $\mathcal{L}_{\text{reg}}$ (weighted by $\gamma$).}
  \label{fig:baseline}
\end{figure}

\subsection{Joint Training (Scenario 2.1)}
\label{sec:joint-training}
\label{sec:baseline}

Zolfaghari \textit{et al.}~\cite{zolfaghari2024sensor} showed that combining these two steps into a single end-to-end training process yields better HAR performance. Rather than freezing the regressor after Step 1, joint training optimizes all three components ($R$, $F$, $C$) simultaneously using a combined objective:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}}
    \label{eq:total_loss}
\end{equation}
where $\alpha$, $\beta$, $\gamma$ are hyperparameters controlling the contribution of each loss term.

At inference time only the real accelerometer branch is used:
\begin{equation}
    \hat{y} = \arg\max_k \, [C(F(\mathbf{a}_{\text{real}}))]
\end{equation}
The simulated data path serves purely as a training-time augmentation mechanism. This ensures that evaluation metrics reflect real-world deployment performance where only physical sensor data is available.

The key advantage is that all losses backpropagate through the entire pipeline. In particular, the classification loss now reaches the regressor, meaning $R$ learns to produce signals that are not just realistic-looking, but \emph{useful for classification}, preserving activity-discriminative information rather than merely mimicking the statistical properties of real accelerometer data.

We refer to this baseline configuration as the \textbf{Scenario 2.1}. As illustrated in \Cref{fig:baseline}, both the real and simulated paths share the same feature extractor $F$ and classifier $C$, with all three loss terms active ($\alpha, \beta, \gamma > 0$). This serves as the foundation for all experimental variants explored in this thesis.

\section{Loss Function Design}
\label{sec:losses}

The training objective combines multiple loss terms that guide different aspects of learning. Each loss component addresses a specific goal, and their relative importance is controlled by three weighting coefficients: $\alpha$, $\beta$, and $\gamma$.

\subsection{Classification Loss}

The primary objective is accurate activity recognition. We apply cross-entropy loss on both the real and simulated accelerometer paths:
\begin{equation}
    \mathcal{L}_{\text{cls}} = \text{CE}(\hat{y}_{\text{real}}, y) + \text{CE}(\hat{y}_{\text{sim}}, y)
\end{equation}
where $\text{CE}$ denotes cross-entropy loss, $y$ is the ground truth label, and $\hat{y}_{\text{real}} = C(F(\mathbf{a}))$, $\hat{y}_{\text{sim}} = C(F(\tilde{\mathbf{a}}))$ are the predicted class distributions from the real and simulated paths respectively. By training on both paths with the same labels, the classifier learns to produce correct predictions regardless of whether the input originates from real or simulated accelerometer data. This loss is weighted by coefficient $\alpha$.

\subsection{Feature Similarity Loss}

To encourage domain-invariant representations, we minimize the distance between feature embeddings of real and simulated data using cosine similarity:
\begin{equation}
    \mathcal{L}_{\text{similarity}} = 1 - \frac{1}{N} \sum_{i=1}^{N} \cos(\mathbf{z}_{\text{real},i}, \mathbf{z}_{\text{sim},i})
\end{equation}
where $\cos(\cdot, \cdot)$ denotes cosine similarity. Crucially, $\mathbf{z}_{\text{real},i}$ and $\mathbf{z}_{\text{sim},i}$ correspond to the same time window: they originate from synchronized pose and accelerometer recordings of the same activity instance. This pairing is essential. If we compared features from unrelated samples, the loss would push the feature extractor toward a solution where all inputs map to similar representations regardless of the underlying activity. By enforcing similarity only between corresponding pairs, the loss encourages the feature extractor to produce consistent representations for the same motion captured through different modalities, while preserving discriminative information across different activities. This loss is weighted by coefficient $\beta$.

\subsection{Regression Loss}

To guide the regressor toward producing realistic accelerometer signals, we minimize the mean squared error between simulated and real data:
\begin{equation}
    \mathcal{L}_{\text{regression}} = \frac{1}{N} \sum_{i=1}^{N} \lVert \mathbf{a}_i - \tilde{\mathbf{a}}_i \rVert^{2}
\end{equation}
This signal-level supervision ensures the regressor learns the mapping from pose to accelerometer in a physically meaningful way. The regression loss is weighted by coefficient $\gamma$.

\subsection{Total Objective}

The baseline training objective combines these three losses:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}}
\end{equation}
where $\alpha$, $\beta$, and $\gamma$ are hyperparameters controlling the contribution of each term. Different experimental configurations selectively enable or disable these terms to study their individual contributions, as detailed in \Cref{sec:scenarios}.

All loss weights ($\alpha, \beta, \gamma$) and optimization details are specified in \Cref{chap:implementation}.

\section{Training Scenarios}
\label{sec:scenarios}

In this thesis we look for methods to increase performance of HAR and will investigate different architectural choices and loss components. We define eight training scenarios. Each scenario modifies the baseline configuration in a specific way, enabling controlled ablation studies and architectural comparisons.

\Cref{tab:scenarios} summarizes all scenarios. We have already introduced Scenario 1 and Scenario 2.1 and in the following subsections, we describe each variant in detail.

\begin{table}[!t]
\centering
\caption{Overview of training scenarios. Each row indicates which components are modified relative to the baseline.}
\label{tab:scenarios}
\begin{tabular}{lp{6cm}}
\hline
\textbf{Scenario} & \textbf{Description} \\
\hline
Scenario 2.1: Baseline & Shared $F$ and $C$; all losses enabled ($\alpha, \beta, \gamma > 0$) \\
Scenario 2.2: MSE Ablation & Baseline with $\gamma = 0$ (no regression loss) \\
Scenario 2.3: Similarity Ablation & Baseline with $\beta = 0$ (no feature similarity loss) \\
Scenario 2.4: Shared rep. \& Sep. Cls. & Separate classifiers $C$ and $C_{\text{sim}}$ for real and simulated paths \\
Scenario 2.5: Sep. rep. \& Shared Cls. & Separate feature extractors $F$ and $F_{\text{sim}}$ for real and simulated paths \\
Scenario 3: Auxiliary Pose & Additional pose-only dataset (NTU) with secondary classifier \\
Scenario 4.1: Feature Discriminator & Adversarial discriminator on feature embeddings \\
Scenario 4.2: Signal Discriminator & Adversarial discriminator on raw accelerometer signals \\
\hline
\end{tabular}
\end{table}

\subsection{Scenario 2.2: Effect of MSE Loss}
\label{sec:scenario-mse-ablation}

This ablation sets $\gamma = 0$, removing the regression loss entirely. The regressor still produces simulated accelerometer signals, but receives no direct signal-level supervision. Instead, it relies solely on gradients backpropagated from the classification and similarity losses. This tests whether explicit signal matching is necessary, or whether task-driven gradients suffice.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-gamma.pdf}
  \caption{Ablation: removing the regression loss ($\gamma = 0$). The regressor $R$ receives no direct signal-level supervision; gradients flow only through the classification and similarity losses. This tests whether task-driven gradients alone can guide meaningful pose-to-IMU simulation.}
  \label{fig:ablation-mse}
\end{figure}

\subsection{Scenario 2.3: Effect of Similarity Loss}
\label{sec:scenario-sim-ablation}

This ablation sets $\beta = 0$, removing the feature similarity loss. The feature extractor no longer receives explicit pressure to align real and simulated representations. This tests whether the shared architecture alone provides sufficient domain alignment, or whether explicit feature matching is beneficial.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-beta.pdf}
  \caption{Ablation: removing the feature similarity loss ($\beta = 0$). The feature extractor $F$ no longer receives explicit pressure to align $\mathbf{z}_{\text{real}}$ and $\mathbf{z}_{\text{sim}}$. Domain alignment relies solely on the shared architecture.}
  \label{fig:ablation-sim}
\end{figure}

\subsection{Scenario 2.4: Shared Representation, Separate Classifiers}
\label{sec:scenario-dual-classifier}

This variant introduces a second classifier $C_{\text{sim}}$ dedicated to the simulated path:
\begin{equation}
    \hat{y}_{\text{sim}} = C_{\text{sim}}(F(\tilde{\mathbf{a}}))
\end{equation}
while the real path continues to use the original classifier $C$. Both classifiers share the same feature extractor $F$. The motivation is that simulated and real features, while similar, may benefit from specialized decision boundaries. At inference time, only $C$ is used with real accelerometer data.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-sharedrep.pdf}
  \caption{Shared representation, separate classifiers. Both paths share the feature extractor $F$, but use separate classifiers: $C$ for real features and $C_{\text{sim}}$ for simulated features. This allows domain-specific decision boundaries while maintaining shared feature representations. At inference, only $C$ is used.}
  \label{fig:dual-classifier}
\end{figure}

\subsection{Scenario 2.5: Separate Representations, Shared Classifier}
\label{sec:scenario-dual-encoder}

This variant introduces a second feature extractor $F_{\text{sim}}$ dedicated to the simulated path:
\begin{equation}
    \mathbf{z}_{\text{sim}} = F_{\text{sim}}(\tilde{\mathbf{a}})
\end{equation}
while the real path uses the original $F$. Both feature extractors feed into the same classifier $C$. The motivation is that real and simulated accelerometer signals may have different characteristics requiring specialized encoding, while the classification task remains unified. At inference time, only $F$ is used.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-sharedcls.pdf}
  \caption{Separate representations, shared classifier. The real path uses feature extractor $F$ while the simulated path uses $F_{\text{sim}}$, allowing domain-specific encoding. Both feed into the same classifier $C$. At inference, only $F$ is used.}
  \label{fig:dual-encoder}
\end{figure}

\subsection{Scenario 3: Auxiliary Pose Data}
\label{sec:scenario-auxiliary}

Compared to the baseline, this scenario introduces an additional pose-only dataset and a secondary classifier, while keeping the main real/sim architecture unchanged.

This scenario augments training with a secondary pose-only dataset (NTU RGB+D) that lacks corresponding real accelerometer data. Although NTU RGB+D contains different activity classes than the primary dataset, we select the same subset of skeletal joints across both datasets to ensure the regressor $R$ receives consistently structured pose inputs. The secondary data flows through the regressor and feature extractor, then to a dedicated secondary classifier $C_{\text{aux}}$:
\begin{equation}
    \mathbf{p}_{\text{aux}} \xrightarrow{R} \tilde{\mathbf{a}}_{\text{aux}} \xrightarrow{F} \mathbf{z}_{\text{aux}} \xrightarrow{C_{\text{aux}}} \hat{y}_{\text{aux}}
\end{equation}
The secondary classification loss is weighted by a separate coefficient $\lambda_{\text{aux}}$:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}} + \lambda_{\text{aux}} \mathcal{L}_{\text{aux}}
\end{equation}
This tests whether additional pose diversity improves the regressor's generalization, even when the auxiliary dataset has different activity classes. 

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-aux.pdf}
  \caption{Auxiliary pose data scenario. A secondary pose-only dataset (NTU RGB+D) augments training. Secondary poses flow through the regressor $R$ and feature extractor $F$ to a dedicated classifier $C_{\text{aux}}$. The auxiliary loss $\mathcal{L}_{\text{aux}}$ (weighted by $\lambda_{\text{aux}}$) provides additional supervision to improve regressor generalization.}
  \label{fig:auxiliary-pose}
\end{figure}

\subsection{Scenario 4.1: Feature-level Discriminator}
\label{sec:scenario-disc-feature}

Scenario 4.1 extends the baseline by adding an adversarial discriminator on feature embeddings, whose architecture is shown in Figure~\ref{fig:disc-feature}. The goal is to explicitly reduce the sim-to-real domain gap by encouraging feature representations extracted from real and simulated accelerometer signals to be indistinguishable. In the following we will define the new components and explain why they can improve HAR task.

\paragraph{Discriminator module.}
We introduce a feature discriminator $D_F$ that maps embeddings to a real/fake logit:
\begin{equation}
    d = D_F(\mathbf{z}) \in \mathbb{R}
    \label{eq:Df}
\end{equation}
Real embeddings are assigned target $t=1$ and simulated embeddings target $t=0$. The discriminator is trained using binary cross-entropy with logits:
\begin{equation}
    \mathcal{L}_{\text{adv}} =
    \text{BCE}(D_F(\mathbf{z}_{\text{real}}), 1)
    + \text{BCE}(D_F(\mathbf{z}_{\text{sim}}), 0)
\end{equation}
We optionally apply label smoothing for the discriminator targets to prevent overconfident domain predictions and to maintain a usable gradient signal throughout training.

We add a discriminator on the learned embeddings to explicitly reduce the sim-to-real domain gap in the representation space used for recognition. By making real and simulated features hard to distinguish, we discourage the classifier from relying on simulation-specific artifacts and promote representations that transfer to real-sensor evaluation.


\paragraph{ACGAN auxiliary classifier.}
In all our experiments, we use an ACGAN-style discriminator that is class-conditional and includes an auxiliary activity classifier head \cite{odena2017conditional}. Concretely, $D_F$ receives the activity label $y$ (embedded and concatenated to $\mathbf{z}$) and outputs both a real/fake logit and activity logits:
\begin{equation}
    (d, \hat{\mathbf{y}}_{D}) = D_F(\mathbf{z}, y), \qquad \hat{\mathbf{y}}_{D} \in \mathbb{R}^{K}
\end{equation}
The auxiliary loss is cross-entropy on both real and simulated embeddings:
\begin{equation}
    \mathcal{L}_{\text{ac}} =
    \text{CE}(\hat{\mathbf{y}}_{D,\text{real}}, y)
    + \text{CE}(\hat{\mathbf{y}}_{D,\text{sim}}, y)
\end{equation}
We use an ACGAN-style auxiliary classification head to keep adversarial alignment class-discriminative. Without the auxiliary head, feature alignment can become class-agnostic and collapse activity structure, producing domain-invariant but less separable embeddings that could degrade macro F1.

\paragraph{Gradient Reversal Layer (GRL).}
To enable end-to-end adversarial learning in a single forward/backward pass, we place a Gradient Reversal Layer (GRL) between the feature extractor and the discriminator \cite{ganin2016domain}. The GRL is the identity function in the forward pass, but multiplies the gradient by $-\lambda_{\text{grl}}$ during backpropagation. As a result, $D_F$ is optimized to minimize $\mathcal{L}_{\text{adv}}$ (and $\mathcal{L}_{\text{ac}}$), while the feature extractor receives an adversarial signal from $\mathcal{L}_{\text{adv}}$ that pushes $\mathbf{z}_{\text{real}}$ and $\mathbf{z}_{\text{sim}}$ toward domain-invariant representations. In our implementation, $\lambda_{\text{grl}}$ can be kept fixed or scheduled over training.

Unlike explicit min--max training, GRL lets us update the discriminator and feature extractor jointly in each iteration (single backward pass), avoiding alternating optimization. Without GRL, training typically requires alternating updates between the discriminator and feature extractor, which is more sensitive to imbalance and can lead to unstable dynamics (e.g., discriminator domination) and weaker alignment.

The overall objective augments the baseline losses with the adversarial and ACGAN auxiliary terms:
\begin{equation}
    \mathcal{L}_{\text{total}} =
    \alpha \mathcal{L}_{\text{cls}}
    + \beta \mathcal{L}_{\text{similarity}}
    + \gamma \mathcal{L}_{\text{regression}}
    + \lambda_{\text{adv}} \mathcal{L}_{\text{adv}}
    + \lambda_{\text{ac}} \mathcal{L}_{\text{ac}}
\end{equation}
At inference time, the discriminator is not used and predictions are produced from the real-accelerometer branch only.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-featdisc.pdf}
  \caption{Feature-level discriminator (Scenario 4.1) with Gradient Reversal Layer (GRL). The discriminator $D_F$ operates on encoder features and predicts a real/fake logit; in our ACGAN setting it additionally predicts the activity class via an auxiliary head. The GRL reverses gradients flowing back to the feature extractor, encouraging domain-invariant representations.}
  \label{fig:disc-feature}
\end{figure}

\subsection{Scenario 4.2: Signal-level Discriminator}
\label{sec:scenario-disc-signal}

Scenario 4.2 extends the baseline by adding an adversarial discriminator directly on raw accelerometer signals. Instead of aligning real and simulated distributions only in feature space, this variant applies adversarial pressure at the signal level, encouraging the regressor to generate realistic accelerometer waveforms. Figure~\ref{fig:disc-signal} shows the training pipeline, and in the following we discuss the new components of this scenario.

\paragraph{Signal discriminator (critic).}
Let $D_S$ be a 1D convolutional critic that maps a window of accelerometer samples to a scalar score. By placing the discriminator at the signal level, we directly penalize unrealistic temporal structure in $\tilde{\mathbf{a}}=R(\mathbf{p})$ and encourage the regressor to match the real sensor distribution, rather than relying on the feature extractor to suppress simulation artifacts.
\begin{equation}
    s = D_S(\mathbf{a}) \in \mathbb{R}
\end{equation}
where higher scores indicate ``more real''. The critic is trained to assign higher scores to real signals $\mathbf{a}$ than to simulated signals $\tilde{\mathbf{a}}$:
\begin{equation}
    \mathcal{L}_D =
    \mathbb{E}[D_S(\tilde{\mathbf{a}})]
    - \mathbb{E}[D_S(\mathbf{a})]
    + \lambda_{\text{gp}} \, \mathcal{L}_{\text{gp}}
\end{equation}
where $\mathcal{L}_{\text{gp}}$ is the gradient penalty term enforcing the 1-Lipschitz constraint in WGAN-GP \cite{gulrajani2017improved}. We use the Wasserstein formulation because it provides more stable, non-saturating gradients for high-dimensional continuous time series than BCE-based adversarial objectives when the real and simulated distributions have limited overlap \cite{arjovsky2017wasserstein,gulrajani2017improved}. Unlike Scenario 4.1, we do not use GRL here; WGAN-GP is trained with alternating critic and generator updates.

\paragraph{ACGAN auxiliary classifier.}
As in Scenario 4.1, we use an ACGAN-style discriminator with an auxiliary activity classifier head \cite{odena2017conditional}. The critic is conditioned on the activity label and outputs both a realness score and activity logits:
\begin{equation}
    (s, \hat{\mathbf{y}}_{D}) = D_S(\mathbf{a}, y), \qquad \hat{\mathbf{y}}_{D} \in \mathbb{R}^{K}
\end{equation}
We define an auxiliary classification loss for the critic on both real and simulated signals:
\begin{equation}
    \mathcal{L}_{\text{ac}}^{D} =
    \text{CE}(\hat{\mathbf{y}}_{D,\text{real}}, y)
    + \text{CE}(\hat{\mathbf{y}}_{D,\text{sim}}, y)
\end{equation}
and a corresponding auxiliary term for the regressor on simulated signals:
\begin{equation}
    \mathcal{L}_{\text{ac}}^{G} = \text{CE}(\hat{\mathbf{y}}_{D,\text{sim}}, y)
\end{equation}
During critic updates, we minimize $\mathcal{L}_D + \lambda_{\text{ac}}\mathcal{L}_{\text{ac}}^{D}$; during regressor updates, we include $\lambda_{\text{ac}}\mathcal{L}_{\text{ac}}^{G}$ to encourage label-consistent synthesis. This auxiliary head encourages class-conditional realism, helping prevent the regressor from producing signals that appear plausible in the aggregate but are ambiguous with respect to activity labels.

\paragraph{Generator loss and optimization.}
The regressor is trained to increase the critic score of generated signals:
\begin{equation}
    \mathcal{L}_{\text{adv}} = -\mathbb{E}[D_S(\tilde{\mathbf{a}})]
\end{equation}
In addition, we include the auxiliary classification term $\mathcal{L}_{\text{ac}}^{G}$ on simulated samples to encourage label-consistent synthesis. We optimize WGAN-GP with alternating updates: for each batch, the critic is updated for $n_{\text{critic}}$ steps while keeping the regressor fixed, and then the regressor is updated for one step while keeping the critic fixed. This alternating scheme is standard for WGAN-GP and avoids the unstable dynamics that can occur when directly reversing gradients at the raw-signal level. In addition, we use staged training by pretraining the regressor with the MSE loss for several epochs before enabling adversarial training to improve stability and avoid early critic domination.

The overall objective for the main network augments the baseline losses with the signal-level adversarial terms:
\begin{equation}
    \mathcal{L}_{\text{total}} =
    \alpha \mathcal{L}_{\text{cls}}
    + \beta \mathcal{L}_{\text{similarity}}
    + \gamma \mathcal{L}_{\text{regression}}
    + \lambda_{\text{adv}} \mathcal{L}_{\text{adv}}
    + \lambda_{\text{ac}} \mathcal{L}_{\text{ac}}^{G}
\end{equation}
At evaluation time, the discriminator is not used and predictions are produced from the real-accelerometer branch only.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-signaldisc.pdf}
  \caption{Signal-level discriminator (Scenario 4.2). The critic $D_S$ operates on raw accelerometer windows and is trained with WGAN-GP to assign higher scores to real signals than to simulated signals $\tilde{\mathbf{a}} = R(\mathbf{p})$. Using alternating critic/generator updates and an ACGAN auxiliary head, this directly pressures the regressor to generate realistic accelerometer waveforms.}
  \label{fig:disc-signal}
\end{figure}
