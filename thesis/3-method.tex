\chapter{Method}
\label{chap:method}

This section describes our method to enhance HAR which focuses on the efficient use of available real and simulated sensor data.
While most other methods consider sensor data simulation and training a HAR classifier as different, independent steps, ours performs both in an end-to-end fashion.

\section{Problem Formulation}
\label{sec:problem}

We address the challenge of improving HAR by leveraging simulated IMU data derived from skeletal pose sequences. This section first describes how the input data is acquired, then formally defines the problem and our approach.

\subsection{Data Acquisition}
\label{sec:data-acquisition}

In this thesis we require synchronized pairs of skeletal pose sequences and accelerometer signals that are labeled with activity classes. These data streams originate from different sensor modalities and undergo preprocessing before use.

\textbf{Accelerometer Data} is a component of Inertial Measurement Units (IMUs) embedded in smartphones, smartwatches, or dedicated wearable devices capture tri-axial acceleration at fixed sampling rates (typically 50--100\,Hz). 

\textbf{Pose Sequences} is extracted from visual sensors, RGB cameras, depth sensors (RGB-D), or multi-view camera arrays (Fig. \ref{fig:3dpose-extraction}). Vision-based pose estimation pipelines first detect 2D keypoints in each frame using convolutional detectors, then lift these to 3D joint coordinates through volumetric representations, using various methods such as triangulation from multiple views, or learned regressors.

\textbf{Synchronization} of multi-sensor recordings require temporal alignment so that each pose frame corresponds to the concurrent accelerometer sample. Datasets such as MM-Fit provide time-synchronized streams, enabling direct pairing of pose and accelerometer windows for the same activity instance \cite{stromback2020mm}. This synchronization is essential for learning the pose-to-accelerometer mapping, as the regressor must observe corresponding motion patterns in both modalities.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/3d-pose-extraction.pdf}
  \caption{Steps in which 3D pose sequence is extracted from frames}
  \label{fig:3dpose-extraction}
\end{figure}

\subsection{Task Definition}

Let $\mathcal{D} = \{(\mathbf{p}_i, \mathbf{a}_i, y_i)\}_{i=1}^{N}$ denote a dataset of synchronized triplets:
\begin{itemize}
    \item $\mathbf{p}_i \in \mathbb{R}^{T \times J \times 3}$: a pose sequence of $T$ timesteps with $J$ skeletal joints in 3D space
    \item $\mathbf{a}_i \in \mathbb{R}^{T \times 3}$: corresponding real accelerometer signal (3-axis)
    \item $y_i \in \{1, \ldots, K\}$: activity class label from $K$ possible activities
\end{itemize}

Our task is to use the pose data $\mathbf{p}$ to generate synthetic accelerometer signals $\tilde{\mathbf{a}}$. Since each pose sequence $\mathbf{p}_i$ is synchronized with its corresponding real accelerometer $\mathbf{a}_i$, they share the same activity label $y_i$. Therefore, the synthetic signal $\tilde{\mathbf{a}}_i$ also inherits this label, effectively augmenting the training set with additional labeled samples. This augmented data can then be used to train a more robust activity classifier.

To achieve this, we define three learned components:

\textbf{Pose-to-IMU Regressor.} A mapping $R: \mathbb{R}^{T \times J \times 3} \rightarrow \mathbb{R}^{T \times 3}$ that transforms pose sequences into simulated accelerometer signals:
\begin{equation}
    \tilde{\mathbf{a}} = R(\mathbf{p})
\end{equation}

\textbf{Feature Extractor.} A mapping $F: \mathbb{R}^{T \times 3} \rightarrow \mathbb{R}^{d}$ that encodes accelerometer signals into $d$-dimensional feature embeddings:
\begin{equation}
    \mathbf{z} = F(\mathbf{a})
\end{equation}

\textbf{Activity Classifier.} A mapping $C: \mathbb{R}^{d} \rightarrow \mathbb{R}^{K}$ that predicts activity classes from feature representations:
\begin{equation}
    \hat{y} = \arg\max_k \, [C(\mathbf{z})]_k
\end{equation}

\subsection{Two-Step Training}
\label{sec:two-step}

The most intuitive way to use simulated data for HAR is a two-step process:

\textbf{Step 1: Train the Regressor.} First, train $R$ to produce realistic simulated accelerometer signals by minimizing the reconstruction error between $\tilde{\mathbf{a}}$ and $\mathbf{a}$:
\begin{equation}
    \mathcal{L}_{\text{regression}} = \frac{1}{N} \sum_{i=1}^{N} \lVert \mathbf{a}_i - R(\mathbf{p}_i) \rVert^{2}
\end{equation}
Once trained, the regressor can generate synthetic accelerometer data $\tilde{\mathbf{a}}_i$ for any pose sequence $\mathbf{p}_i$.

\textbf{Step 2: Train HAR with Augmented Data.} Freeze $R$ and use it to generate synthetic accelerometer signals. Then train $F$ and $C$ on both real and simulated data:
\begin{equation}
    \mathbf{z}_{\text{real}} = F(\mathbf{a}), \quad \mathbf{z}_{\text{sim}} = F(\tilde{\mathbf{a}})
\end{equation}
\begin{equation}
    \hat{y}_{\text{real}} = \arg\max_k [C(\mathbf{z}_{\text{real}})], \quad \hat{y}_{\text{sim}} = \arg\max_k [C(\mathbf{z}_{\text{sim}})]
\end{equation}
Since both $\mathbf{a}$ and $\tilde{\mathbf{a}}$ share the same label $y$, the classifier effectively trains on an augmented dataset. The training objective in this step combines a classification loss on both paths and optionally a feature similarity loss to encourage domain alignment:
\begin{equation}
    \mathcal{L}_{\text{cls}} = \text{CE}(\hat{y}_{\text{real}}, y) + \text{CE}(\hat{y}_{\text{sim}}, y)
\end{equation}
\begin{equation}
    \mathcal{L}_{\text{similarity}} = 1 - \cos(\mathbf{z}_{\text{real}}, \mathbf{z}_{\text{sim}})
\end{equation}
where CE denotes cross-entropy loss and $\cos(\cdot, \cdot)$ denotes cosine similarity. The similarity loss encourages $F$ to produce similar representations for corresponding real and simulated samples, reducing the domain gap.

This sequential approach treats pose-to-IMU regression and activity classification as independent tasks.

\subsection{Joint Training (Baseline)}
\label{sec:joint-training}
\label{sec:baseline}

Zolfaghari \textit{et al.}~\cite{zolfaghari2024sensor} showed that combining these two steps into a single end-to-end training process yields better HAR performance. Rather than freezing the regressor after Step 1, joint training optimizes all three components ($R$, $F$, $C$) simultaneously using a combined objective:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}}
    \label{eq:total_loss}
\end{equation}
where $\alpha$, $\beta$, $\gamma$ are hyperparameters controlling the contribution of each loss term.

The key advantage is that all losses backpropagate through the entire pipeline. In particular, the classification loss now reaches the regressor, meaning $R$ learns to produce signals that are not just realistic-looking, but \emph{useful for classification}---preserving activity-discriminative information rather than merely mimicking the statistical properties of real accelerometer data.

We refer to this configuration as the \textbf{Baseline} scenario. As illustrated in \Cref{fig:baseline}, both the real and simulated paths share the same feature extractor $F$ and classifier $C$, with all three loss terms active ($\alpha, \beta, \gamma > 0$). This serves as the foundation for all experimental variants explored in this thesis.

\subsection{Evaluation Protocol}

Critically, at inference time only the real accelerometer branch is used:
\begin{equation}
    \hat{y} = \arg\max_k \, [C(F(\mathbf{a}_{\text{real}}))]_k
\end{equation}
The simulated data path ($R$, and optionally separate $F_{\text{sim}}$, $C_{\text{sim}}$) serves purely as a training-time augmentation mechanism. This ensures that evaluation metrics reflect real-world deployment performance where only physical sensor data is available.

\section{System Architecture}
\label{sec:architecture}

Our framework employs a two-stream architecture that processes both real and simulated accelerometer data during training. This section describes the baseline configuration, which serves as the foundation for all experimental variants explored in this work.

All real accelerometer signals $\mathbf{a}$ and pose sequences $\mathbf{p}$ undergo preprocessing (normalization and standardization) as described in \Cref{chap:implementation}.  
Simulated accelerometer signals $\tilde{\mathbf{a}}$ are generated by the regressor $R$ in this normalized space and are not subject to additional preprocessing.

\subsection{Two-Stream Design}

The architecture comprises three core components that operate on parallel data streams during training:

\begin{enumerate}
    \item \textbf{Pose-to-IMU Regressor} ($R$): Transforms skeleton pose sequences into simulated accelerometer signals
    \item \textbf{Feature Extractor} ($F$): Encodes accelerometer signals (real or simulated) into fixed-dimensional feature representations
    \item \textbf{Activity Classifier} ($C$): Maps feature representations to activity class predictions
\end{enumerate}

\Cref{fig:baseline} illustrates the baseline architecture. During each training iteration, a batch contains synchronized triplets $(\mathbf{p}, \mathbf{a}, y)$ of pose sequences, real accelerometer data, and activity labels. The data flows through two parallel paths:

\textbf{Real Path:}
\begin{equation}
    \mathbf{a} \xrightarrow{F} \mathbf{z}_{\text{real}} \xrightarrow{C} \hat{y}_{\text{real}}
\end{equation}

\textbf{Simulated Path:}
\begin{equation}
    \mathbf{p} \xrightarrow{R} \tilde{\mathbf{a}} \xrightarrow{F} \mathbf{z}_{\text{sim}} \xrightarrow{C} \hat{y}_{\text{sim}}
\end{equation}

where $\mathbf{z}_{\text{real}}, \mathbf{z}_{\text{sim}} \in \mathbb{R}^{d}$ are the $d$-dimensional feature embeddings extracted by $F$.

In the baseline configuration, both paths share the same feature extractor $F$ and classifier $C$. This weight sharing encourages the network to learn domain-invariant representations that perform well regardless of whether the input is real or simulated accelerometer data.

\subsection{Component Interactions}

The three components interact through multiple loss signals that provide complementary supervision:

\begin{itemize}
    \item The \textbf{regressor} $R$ receives gradients from the regression loss (comparing $\tilde{\mathbf{a}}$ to $\mathbf{a}$) and, through backpropagation, from downstream classification losses
    \item The \textbf{feature extractor} $F$ receives gradients from both classification paths and optionally from a feature similarity loss that encourages $\mathbf{z}_{\text{real}} \approx \mathbf{z}_{\text{sim}}$
    \item The \textbf{classifier} $C$ receives supervision from activity labels on both real and simulated features
\end{itemize}

This joint optimization allows each component to benefit from the others: the regressor learns to produce signals that are not only similar to real data but also activity-discriminative, while the feature extractor learns representations robust to the domain gap between real and simulated inputs.

\section{Loss Function Design}
\label{sec:losses}

The training objective combines multiple loss terms that guide different aspects of learning. Each loss component addresses a specific goal, and their relative importance is controlled by three weighting coefficients: $\alpha$, $\beta$, and $\gamma$.

\subsection{Classification Loss}

The primary objective is accurate activity recognition. We apply cross-entropy loss on both the real and simulated accelerometer paths:
\begin{equation}
    \mathcal{L}_{\text{cls}} = -\sum_{i=1}^{N} \sum_{k=1}^{K} w_k \, y_{i,k} \left( \log \hat{y}_{i,k}^{\text{real}} + \log \hat{y}_{i,k}^{\text{sim}} \right)
\end{equation}
where $y_{i,k}$ is the one-hot encoded ground truth, $\hat{y}_{i,k}^{\text{real}} = [C(F(\mathbf{a}_i))]_k$ and $\hat{y}_{i,k}^{\text{sim}} = [C(F(\tilde{\mathbf{a}}_i))]_k$ are the predicted probabilities from the real and simulated paths respectively, and $w_k$ are optional class weights to handle imbalanced datasets. By training on both paths with the same labels, the classifier learns to produce correct predictions regardless of whether the input originates from real or simulated accelerometer data. This loss is weighted by coefficient $\alpha$.

\subsection{Feature Similarity Loss}

To encourage domain-invariant representations, we minimize the distance between feature embeddings of real and simulated data using cosine similarity:
\begin{equation}
    \mathcal{L}_{\text{similarity}} = 1 - \frac{1}{N} \sum_{i=1}^{N} \cos(\mathbf{z}_{\text{real},i}, \mathbf{z}_{\text{sim},i})
\end{equation}
where $\cos(\cdot, \cdot)$ denotes cosine similarity. This loss operates at the feature level, pushing the feature extractor to produce similar representations for corresponding real and simulated samples. This loss is weighted by coefficient $\beta$.

\subsection{Regression Loss}

To guide the regressor toward producing realistic accelerometer signals, we minimize the mean squared error between simulated and real data:
\begin{equation}
    \mathcal{L}_{\text{regression}} = \frac{1}{N} \sum_{i=1}^{N} \lVert \mathbf{a}_i - \tilde{\mathbf{a}}_i \rVert^{2}
\end{equation}
This signal-level supervision ensures the regressor learns the mapping from pose to accelerometer in a physically meaningful way. The regression loss is weighted by coefficient $\gamma$.

\subsection{Total Objective}

The baseline training objective combines these three losses:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}}
    \label{eq:total_loss}
\end{equation}
where $\alpha$, $\beta$, and $\gamma$ are hyperparameters controlling the contribution of each term. Different experimental configurations selectively enable or disable these terms to study their individual contributions, as detailed in \Cref{sec:scenarios}.

All loss weights ($\alpha, \beta, \gamma, \lambda_{\text{aux}}, \lambda_{\text{adv}}$) and optimization details are specified in \Cref{chap:implementation}.

\section{Training Scenarios}
\label{sec:scenarios}

To systematically investigate the contributions of different architectural choices and loss components, we define eight training scenarios. Each scenario modifies the baseline configuration in a specific way, enabling controlled ablation studies and architectural comparisons.

\Cref{tab:scenarios} summarizes all scenarios. The following subsections describe each variant in detail.

\begin{table}[!t]
\centering
\caption{Overview of training scenarios. Each row indicates which components are modified relative to the baseline.}
\label{tab:scenarios}
\begin{tabular}{lp{6cm}}
\hline
\textbf{Scenario} & \textbf{Description} \\
\hline
Baseline & Shared $F$ and $C$; all losses enabled ($\alpha, \beta, \gamma > 0$) \\
Ablation: MSE & Baseline with $\gamma = 0$ (no regression loss) \\
Ablation: Similarity & Baseline with $\beta = 0$ (no feature similarity loss) \\
Shared rep. \& Sep. Cls. & Separate classifiers $C$ and $C_{\text{sim}}$ for real and simulated paths \\
Sep. rep. \& Shared Cls. & Separate feature extractors $F$ and $F_{\text{sim}}$ for real and simulated paths \\
Auxiliary Pose & Additional pose-only dataset (NTU) with secondary classifier \\
Feature Discriminator & Adversarial discriminator on feature embeddings \\
Signal Discriminator & Adversarial discriminator on raw accelerometer signals \\
\hline
\end{tabular}
\end{table}

\subsection{Baseline}
\label{sec:scenario-baseline}

The baseline configuration uses shared weights for both the feature extractor and classifier across real and simulated paths. All three loss terms are active: classification ($\alpha > 0$), feature similarity ($\beta > 0$), and regression ($\gamma > 0$). This represents the simplest form of joint training where the network must learn domain-invariant representations through weight sharing alone.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-baseline.pdf}
  \caption{Baseline architecture with shared feature extractor $F$ and classifier $C$. Real accelerometer data $\mathbf{a}$ and simulated data $\tilde{\mathbf{a}}$ (from regressor $R$) pass through the same network. Three losses guide training: classification loss $\mathcal{L}_{\text{cls}}$ (weighted by $\alpha$), feature similarity loss $\mathcal{L}_{\text{sim}}$ (weighted by $\beta$), and regression loss $\mathcal{L}_{\text{reg}}$ (weighted by $\gamma$).}
  \label{fig:baseline}
\end{figure}

\subsection{Ablation: Effect of MSE Loss}
\label{sec:scenario-mse-ablation}

This ablation sets $\gamma = 0$, removing the regression loss entirely. The regressor still produces simulated accelerometer signals, but receives no direct signal-level supervision. Instead, it relies solely on gradients backpropagated from the classification and similarity losses. This tests whether explicit signal matching is necessary, or whether task-driven gradients suffice.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-gamma.pdf}
  \caption{Ablation: removing the regression loss ($\gamma = 0$). The regressor $R$ receives no direct signal-level supervision; gradients flow only through the classification and similarity losses. This tests whether task-driven gradients alone can guide meaningful pose-to-IMU simulation.}
  \label{fig:ablation-mse}
\end{figure}

\subsection{Ablation: Effect of Similarity Loss}
\label{sec:scenario-sim-ablation}

This ablation sets $\beta = 0$, removing the feature similarity loss. The feature extractor no longer receives explicit pressure to align real and simulated representations. This tests whether the shared architecture alone provides sufficient domain alignment, or whether explicit feature matching is beneficial.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-beta.pdf}
  \caption{Ablation: removing the feature similarity loss ($\beta = 0$). The feature extractor $F$ no longer receives explicit pressure to align $\mathbf{z}_{\text{real}}$ and $\mathbf{z}_{\text{sim}}$. Domain alignment relies solely on the shared architecture.}
  \label{fig:ablation-sim}
\end{figure}

\subsection{Shared Representation, Separate Classifiers}
\label{sec:scenario-dual-classifier}

This variant introduces a second classifier $C_{\text{sim}}$ dedicated to the simulated path:
\begin{equation}
    \hat{y}_{\text{sim}} = C_{\text{sim}}(F(\tilde{\mathbf{a}}))
\end{equation}
while the real path continues to use the original classifier $C$. Both classifiers share the same feature extractor $F$. The motivation is that simulated and real features, while similar, may benefit from specialized decision boundaries. At inference time, only $C$ is used with real accelerometer data.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-sharedrep.pdf}
  \caption{Shared representation, separate classifiers. Both paths share the feature extractor $F$, but use separate classifiers: $C$ for real features and $C_{\text{sim}}$ for simulated features. This allows domain-specific decision boundaries while maintaining shared feature representations. At inference, only $C$ is used.}
  \label{fig:dual-classifier}
\end{figure}

\subsection{Separate Representations, Shared Classifier}
\label{sec:scenario-dual-encoder}

This variant introduces a second feature extractor $F_{\text{sim}}$ dedicated to the simulated path:
\begin{equation}
    \mathbf{z}_{\text{sim}} = F_{\text{sim}}(\tilde{\mathbf{a}})
\end{equation}
while the real path uses the original $F$. Both feature extractors feed into the same classifier $C$. The motivation is that real and simulated accelerometer signals may have different characteristics requiring specialized encoding, while the classification task remains unified. At inference time, only $F$ is used.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-sharedcls.pdf}
  \caption{Separate representations, shared classifier. The real path uses feature extractor $F$ while the simulated path uses $F_{\text{sim}}$, allowing domain-specific encoding. Both feed into the same classifier $C$. At inference, only $F$ is used.}
  \label{fig:dual-encoder}
\end{figure}

\subsection{Auxiliary Pose Data}
\label{sec:scenario-auxiliary}

Compared to the baseline, this scenario introduces an additional pose-only dataset and a secondary classifier, while keeping the main real/sim architecture unchanged.

This scenario augments training with a secondary pose-only dataset (NTU RGB+D) that lacks corresponding real accelerometer data. Although NTU RGB+D contains different activity classes than the primary dataset, we select the same subset of skeletal joints across both datasets to ensure the regressor $R$ receives consistently structured pose inputs. The secondary data flows through the regressor and feature extractor, then to a dedicated secondary classifier $C_{\text{aux}}$:
\begin{equation}
    \mathbf{p}_{\text{aux}} \xrightarrow{R} \tilde{\mathbf{a}}_{\text{aux}} \xrightarrow{F_{\text{sim}}} \mathbf{z}_{\text{aux}} \xrightarrow{C_{\text{aux}}} \hat{y}_{\text{aux}}
\end{equation}
The secondary classification loss is weighted by a separate coefficient $\lambda_{\text{aux}}$:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}} + \lambda_{\text{aux}} \mathcal{L}_{\text{aux}}
\end{equation}
This tests whether additional pose diversity improves the regressor's generalization, even when the auxiliary dataset has different activity classes. 

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-aux.pdf}
  \caption{Auxiliary pose data scenario. A secondary pose-only dataset (NTU RGB+D) augments training. Secondary poses flow through the regressor $R$ and feature extractor $F_{\text{sim}}$ to a dedicated classifier $C_{\text{aux}}$. The auxiliary loss $\mathcal{L}_{\text{aux}}$ (weighted by $\lambda_{\text{aux}}$) provides additional supervision to improve regressor generalization.}
  \label{fig:auxiliary-pose}
\end{figure}

\subsection{Feature-level Discriminator}
\label{sec:scenario-disc-feature}

This scenario extends the baseline by adding an adversarial discriminator on feature embeddings. Additionally, this scenario employs separate feature extractors ($F$ for real, $F_{\text{sim}}$ for simulated) and separate classifiers ($C$ for real, $C_{\text{sim}}$ for simulated) to allow each path to specialize while the discriminator enforces domain alignment at the feature level.

The discriminator $D$ operates on feature embeddings and attempts to distinguish real features $\mathbf{z}_{\text{real}}$ from simulated features $\mathbf{z}_{\text{sim}}$:
\begin{equation}
    D: \mathbb{R}^d \rightarrow [0, 1]
\end{equation}
where output near 1 indicates ``real'' and near 0 indicates ``simulated.''

A Gradient Reversal Layer (GRL) enables end-to-end training: during the forward pass, GRL acts as identity; during backpropagation, it negates gradients by a factor $\lambda_{\text{adv}}$. This creates an adversarial signal that pushes the feature extractor to produce domain-invariant features that fool the discriminator.

The adversarial loss follows the standard binary cross-entropy formulation:
\begin{equation}
    \mathcal{L}_{\text{adv}} = -\mathbb{E}[\log D(\mathbf{z}_{\text{real}})] - \mathbb{E}[\log(1 - D(\mathbf{z}_{\text{sim}}))]
\end{equation}
The discriminator $D$ is trained to minimize this loss (correctly classifying domains), while the GRL causes the feature extractor to maximize it (producing indistinguishable features). The total training objective becomes:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}} - \lambda_{\text{adv}} \mathcal{L}_{\text{adv}}
\end{equation}
where the negative sign reflects the adversarial nature: the main network minimizes $\mathcal{L}_{\text{total}}$ while effectively maximizing $\mathcal{L}_{\text{adv}}$ through the GRL.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-featdisc.pdf}
  \caption{Feature-level discriminator with Gradient Reversal Layer (GRL). The discriminator $D$ classifies features as real or simulated. During backpropagation, the GRL negates gradients (multiplies by $-\lambda$), creating an adversarial signal that encourages $F$ to produce domain-invariant features that fool $D$.}
  \label{fig:disc-feature}
\end{figure}

\subsection{Signal-level Discriminator}
\label{sec:scenario-disc-signal}

In contrast to feature-level discrimination, this variant applies adversarial supervision directly at the signal level, primarily affecting the regressor. Like the feature-level variant, this scenario also employs separate feature extractors ($F$ for real, $F_{\text{sim}}$ for simulated) and separate classifiers ($C$ for real, $C_{\text{sim}}$ for simulated).

The discriminator operates on raw accelerometer signals rather than features:
\begin{equation}
    D: \mathbb{R}^{T \times 3} \rightarrow [0, 1]
\end{equation}
The discriminator distinguishes real accelerometer data $\mathbf{a}$ from simulated data $\tilde{\mathbf{a}}$ produced by the regressor. This directly pressures the regressor to produce realistic-looking signals, complementing the MSE loss.

The adversarial loss mirrors the feature-level formulation:
\begin{equation}
    \mathcal{L}_{\text{adv}} = -\mathbb{E}[\log D(\mathbf{a})] - \mathbb{E}[\log(1 - D(\tilde{\mathbf{a}}))]
\end{equation}
and the total objective follows the same structure:
\begin{equation}
    \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{cls}} + \beta \mathcal{L}_{\text{similarity}} + \gamma \mathcal{L}_{\text{regression}} - \lambda_{\text{adv}} \mathcal{L}_{\text{adv}}
\end{equation}

The key difference from feature-level discrimination is where the adversarial gradient flows: here it primarily affects the regressor $R$, encouraging it to generate signals indistinguishable from real sensor data, while feature-level discrimination primarily affects the feature extractor $F$.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Thesis_Template_DE_EN/BA_MA_English/Figures/arch-signaldisc.pdf}
  \caption{Signal-level discriminator. Unlike feature-level discrimination, $D$ operates on raw accelerometer signals $\mathbf{a}$ vs.\ $\tilde{\mathbf{a}}$. The GRL reverses gradients to the regressor $R$, directly pressuring it to produce realistic accelerometer waveforms indistinguishable from real sensor data.}
  \label{fig:disc-signal}
\end{figure}