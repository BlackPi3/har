{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from utils import config\n",
    "from utils import utils\n",
    "from utils.models import Regressor, FeatureExtractor, ActivityClassifier\n",
    "\n",
    "if config.dataset == config.Dataset.MMFIT:\n",
    "    import utils.mmfit_data as mmfit\n",
    "    window_length = config.sensor_window_length\n",
    "elif config.dataset == config.Dataset.MHAD:\n",
    "    import utils.mhad_data as mhad\n",
    "    window_length = config.mhad_window_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ../train_out/22.02/16.12_pose2imu[1000000](model).pth\n"
     ]
    }
   ],
   "source": [
    "# # >>> REGRESSOR <<< #\n",
    "pose2imu_model = Regressor(\n",
    "    in_ch=config.in_ch, num_joints=config.num_joints, window_length=window_length\n",
    ").to(config.device)\n",
    "best_seed = config.best_pose2imu_seed # best_seed of best model\n",
    "model_name = config.pose2imu_model_name + f\"[{best_seed}](model).pth\"\n",
    "latest_model = utils.find_latest_model(model_name)\n",
    "print(f\"loading: {latest_model}\")\n",
    "pose2imu_model.load_state_dict(torch.load(latest_model, map_location=config.device))\n",
    "pose2imu_model.eval() # we're not training this model\n",
    "\n",
    "fe_model = FeatureExtractor().to(config.device, non_blocking=True)\n",
    "ac_model = ActivityClassifier(f_in=config.ac_fin, n_classes=config.ac_num_classes).to(config.device, non_blocking=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "params = list(fe_model.parameters()) + list(ac_model.parameters())\n",
    "optimizer = torch.optim.Adam(params=params, lr=config.lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- TEST f_in\n",
    "# fe_model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for pose, acc, labels in mmfit.train_loader:\n",
    "#         out = fe_model(acc)\n",
    "#         print(out.shape)\n",
    "#         out = out.view(out.shape[0], -1)\n",
    "#         print(out.shape)\n",
    "#         out = ac_model(out)\n",
    "#         print(out.shape)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "ERROR:tornado.general:SEND Error: Host unreachable\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m ac_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pose, acc, labels \u001b[38;5;129;01min\u001b[39;00m mmfit\u001b[38;5;241m.\u001b[39mval_loader:\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;66;03m# -- Move to GPU\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         pose \u001b[38;5;241m=\u001b[39m pose\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     87\u001b[0m         acc \u001b[38;5;241m=\u001b[39m acc\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mm-fit/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/mm-fit/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mm-fit/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/mm-fit/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mm-fit/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/mm-fit/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/mm-fit/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m wait([\u001b[38;5;28mself\u001b[39m], timeout)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/mm-fit/lib/python3.11/multiprocessing/connection.py:947\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    944\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 947\u001b[0m     ready \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/mm-fit/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# >>> Training <<< #\n",
    "train_loss_history, train_f1_history, train_accuracy_history = [], [], []\n",
    "val_loss_history, val_f1_history, val_accuracy_history = [], [], []\n",
    "\n",
    "best_fe_model_state, best_ac_model_state = None, None\n",
    "best_epoch = float('inf')\n",
    "best_val_f1 = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "epochs = config.epochs\n",
    "patience = config.patience\n",
    "epochs_no_improve = 0\n",
    "\n",
    "log = ''\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # - TRAIN\n",
    "    total_train_loss = 0\n",
    "    all_pred_labels, all_true_labels = [], []\n",
    "    total_predictions, correct_predictions = 0, 0\n",
    "\n",
    "    fe_model.train()\n",
    "    ac_model.train()\n",
    "    for pose, acc, labels in mmfit.train_loader:\n",
    "        \"\"\"\n",
    "        pose: (batch_size, 3, num_joints, sensor_window_length)\n",
    "        acc: (batch_size, 3, sensor_window_length)\n",
    "        \"\"\"\n",
    "        # -- Move to GPU\n",
    "        pose = pose.to(config.device, non_blocking=True)\n",
    "        acc = acc.to(config.device, non_blocking=True)\n",
    "        labels = labels.to(config.device, non_blocking=True)\n",
    "\n",
    "        # -- Forward pass\n",
    "        # --- Regressor\n",
    "        if config.mode == config.Mode.SIM:\n",
    "            acc = pose2imu_model(pose)  # IMPORTANT SIM acc\n",
    "        # --- Feature Extractor\n",
    "        acc_features = fe_model(acc)\n",
    "        # --- Activity Classifier\n",
    "        label_logits = ac_model(acc_features)\n",
    "\n",
    "        # -- Loss\n",
    "        loss = criterion(label_logits, labels)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # -- F1\n",
    "        pred_labels = torch.argmax(label_logits, dim=1)\n",
    "        all_pred_labels.extend(pred_labels.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # -- Accuracy\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (pred_labels == labels).sum().item()\n",
    "\n",
    "        # -- Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # -- Loss\n",
    "    average_train_loss = total_train_loss / len(mmfit.train_loader)\n",
    "    train_loss_history.append(average_train_loss)\n",
    "\n",
    "    # -- F1\n",
    "    train_f1 = f1_score(all_true_labels, all_pred_labels, average=\"macro\")\n",
    "    train_f1_history.append(train_f1)\n",
    "\n",
    "    # -- Accuracy\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "    # - VAL\n",
    "    total_val_loss = 0\n",
    "    all_pred_labels, all_true_labels = [], []\n",
    "    total_predictions, correct_predictions = 0, 0\n",
    "\n",
    "    fe_model.eval()\n",
    "    ac_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for pose, acc, labels in mmfit.val_loader:\n",
    "            # -- Move to GPU\n",
    "            pose = pose.to(config.device, non_blocking=True)\n",
    "            acc = acc.to(config.device, non_blocking=True)\n",
    "            labels = labels.to(config.device, non_blocking=True)\n",
    "\n",
    "            # -- Forward pass\n",
    "            # --- Feature Extractor\n",
    "            acc_features = fe_model(acc)\n",
    "            # --- Activity Classifier\n",
    "            label_logits = ac_model(acc_features)\n",
    "\n",
    "            # -- Loss\n",
    "            loss = criterion(label_logits, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # -- F1\n",
    "            pred_labels = torch.argmax(label_logits, dim=1)\n",
    "            all_pred_labels.extend(pred_labels.cpu().numpy())\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # -- Accuracy\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (pred_labels == labels).sum().item()\n",
    "\n",
    "    # -- Loss\n",
    "    average_val_loss = total_val_loss / len(mmfit.val_loader)\n",
    "    val_loss_history.append(average_val_loss)\n",
    "\n",
    "    # -- F1\n",
    "    val_f1 = f1_score(all_true_labels, all_pred_labels, average=\"macro\")\n",
    "    val_f1_history.append(val_f1)\n",
    "\n",
    "    # -- Accuracy\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "    val_accuracy_history.append(val_accuracy)\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "    out = (f\"Epoch {epoch+1}/{epochs}\" +\n",
    "           f\"\\nTRAIN Total Loss: {average_train_loss:.4f}\" +\n",
    "           f'\\nTRAIN F1: {train_f1:.4f}, Accuracy: {train_accuracy:.4f}' +\n",
    "           f'\\nVAL Total Loss: {average_val_loss:.4f}' +\n",
    "           f'\\nVAL F1: {val_f1:.4f}, Accuracy: {val_accuracy:.4f}' +\n",
    "           f'\\n----------------------------------------------------\\n')\n",
    "\n",
    "    print(out)\n",
    "\n",
    "    # - Early stop\n",
    "    if best_val_f1 < val_f1:\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        best_val_f1 = val_f1\n",
    "        best_val_acc = val_accuracy\n",
    "        best_epoch = epoch\n",
    "        \n",
    "        best_fe_model_state = copy.deepcopy(fe_model.state_dict())\n",
    "        best_ac_model_state = copy.deepcopy(ac_model.state_dict())\n",
    "        \n",
    "        log = out\n",
    "\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # Training early stop\n",
    "    if epochs_no_improve == patience:\n",
    "        # -- Load best model\n",
    "        fe_model.load_state_dict(best_fe_model_state)\n",
    "        ac_model.load_state_dict(best_ac_model_state)\n",
    "\n",
    "        break\n",
    "\n",
    "    scheduler.step(average_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Test <<< #\n",
    "# - Test\n",
    "total_loss = 0\n",
    "loss_history, f1_history, accuracy_history = [], [], []\n",
    "all_pred_labels, all_true_labels = [], []\n",
    "total_predictions, correct_predictions = 0, 0\n",
    "\n",
    "fe_model.eval()\n",
    "ac_model.eval()\n",
    "with torch.no_grad():\n",
    "    for pose, acc, labels in mmfit.test_loader:\n",
    "        # -- Move to GPU\n",
    "        acc = acc.to(config.device, non_blocking=True)\n",
    "        labels = labels.to(config.device, non_blocking=True)\n",
    "\n",
    "        # -- Forward pass\n",
    "        # --- Feature Extractor\n",
    "        acc_features = fe_model(acc)\n",
    "        # --- Activity Classifier\n",
    "        label_logits = ac_model(acc_features)\n",
    "\n",
    "        # -- Loss\n",
    "        loss = criterion(label_logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # -- F1 \n",
    "        pred_labels = torch.argmax(label_logits, dim=1)\n",
    "        all_pred_labels.extend(pred_labels.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # -- Accuracy\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (pred_labels == labels).sum().item()\n",
    "\n",
    "# -- Loss\n",
    "average_loss = total_loss / len(mmfit.test_loader)\n",
    "loss_history.append(average_loss)\n",
    "\n",
    "# -- F1\n",
    "f1 = f1_score(all_true_labels, all_pred_labels, average=\"macro\")\n",
    "\n",
    "# -- Accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "log += f\"Test F1: {f1:.4f}, Test Accuracy: {accuracy:.4f}\" + \\\n",
    "        f'\\n----------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Save models and metrics <<< #\n",
    "if config.mode == config.Mode.REAL:\n",
    "    mode = \"real\"\n",
    "elif config.mode == config.Mode.SIM:\n",
    "    mode = \"sim\"\n",
    "elif config.mode == config.Mode.COMB:\n",
    "    mode = \"comb\"\n",
    "\n",
    "prefix = config.scenario1_name + \"[s=\" + str(utils.args.seed) + \"]\" + \"[m=\" + mode + \"]\"\n",
    "\n",
    "# - Models\n",
    "# file_name = config.ae_model_name + prefix + '(model)'\n",
    "# utils.save_model(best_ae_model_state, file_name)\n",
    "\n",
    "# file_name = config.fc_model_name + prefix + '(model)'\n",
    "# utils.save_model(best_fc_model_state, file_name)\n",
    "\n",
    "# - Loss\n",
    "metric = \"Total Loss\"\n",
    "file_name = '1_' + prefix + \"(\" + metric + \")\"\n",
    "utils.save_plot(\n",
    "    epochs=epoch,\n",
    "    best_epoch=best_epoch,\n",
    "    train_metric_history=train_loss_history,\n",
    "    val_metric_history=val_loss_history,\n",
    "    metric=metric,\n",
    "    file_name=file_name,\n",
    ")\n",
    "\n",
    "# - F1\n",
    "metric = \"F1\"\n",
    "file_name = '2_' + prefix + \"(\" + metric + \")\"\n",
    "utils.save_plot(\n",
    "    epochs=epoch,\n",
    "    best_epoch=best_epoch,\n",
    "    train_metric_history=train_f1_history,\n",
    "    val_metric_history=val_f1_history,\n",
    "    metric=metric,\n",
    "    file_name=file_name,\n",
    ")\n",
    "\n",
    "# - Accuracy\n",
    "metric = \"Accuracy\"\n",
    "file_name = '3_' + prefix + \"(\" + metric + \")\"\n",
    "utils.save_plot(\n",
    "    epochs=epoch,\n",
    "    best_epoch=best_epoch,\n",
    "    train_metric_history=train_accuracy_history,\n",
    "    val_metric_history=val_accuracy_history,\n",
    "    metric=metric,\n",
    "    file_name=file_name,\n",
    ")\n",
    "\n",
    "# - Log\n",
    "log += prefix\n",
    "file_name = '4_' + prefix + \"(Log)\"\n",
    "utils.save_log(log=log, file_name=file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm-fit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
