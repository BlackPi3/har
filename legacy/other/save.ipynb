{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.models import Regressor\n",
    "# from utils.mmfit_data import unfold_acc, train_datasets, val_datasets, SequentialStridedSampler, TRAIN_W_IDS, VAL_W_IDS\n",
    "import utils.mmfit_data as mmfit\n",
    "from utils import config\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ../train_out/19.02/03.18_pose2imu[2](model).pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> CNN <<< #\n",
    "pose2imu_model = Regressor(\n",
    "    in_ch=config.in_ch, num_joints=config.num_joints, window_length=config.sensor_window_length\n",
    ").to(config.device)\n",
    "best_seed = config.best_pose2imu_seed\n",
    "name = config.pose2imu_model_name + f\"[{best_seed}](model).pth\"\n",
    "latest_model = utils.find_latest_model(name)\n",
    "print(f\"loading: {latest_model}\")\n",
    "pose2imu_model.load_state_dict(torch.load(latest_model, map_location=config.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/zolfaghari/vidgensense/src/save.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://serv-9218.kl.dfki.de:60524/home/zolfaghari/vidgensense/src/save.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m real_acc_data \u001b[39m=\u001b[39m real_acc[:, \u001b[39m2\u001b[39m:]\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)  \u001b[39m# (3, N)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://serv-9218.kl.dfki.de:60524/home/zolfaghari/vidgensense/src/save.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m pred_acc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mempty_like(real_acc_data)\u001b[39m.\u001b[39mto(config\u001b[39m.\u001b[39mdevice) \u001b[39m# (3, N)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://serv-9218.kl.dfki.de:60524/home/zolfaghari/vidgensense/src/save.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m mmfit\u001b[39m.\u001b[39;49munfold(model\u001b[39m=\u001b[39;49mpose2imu_model, dataset\u001b[39m=\u001b[39;49mdataset, pred_acc\u001b[39m=\u001b[39;49mpred_acc)\n\u001b[1;32m     <a href='vscode-notebook-cell://serv-9218.kl.dfki.de:60524/home/zolfaghari/vidgensense/src/save.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# save pred_acc\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://serv-9218.kl.dfki.de:60524/home/zolfaghari/vidgensense/src/save.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m sim_acc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mempty_like(real_acc)  \u001b[39m# (N, 5)\u001b[39;00m\n",
      "File \u001b[0;32m/home/zolfaghari/vidgensense/src/utils/mmfit_data.py:115\u001b[0m, in \u001b[0;36munfold\u001b[0;34m(model, dataset, pred_acc)\u001b[0m\n\u001b[1;32m    113\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m    114\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mfor\u001b[39;00m pose, _, _ \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m    117\u001b[0m         batch_pred_acc \u001b[39m=\u001b[39m model(pose)  \u001b[39m# (batch, 3, N)\u001b[39;00m\n\u001b[1;32m    119\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_pred_acc\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):  \u001b[39m# for each batch\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/home/zolfaghari/vidgensense/src/utils/mmfit_data.py:62\u001b[0m, in \u001b[0;36mMMFit.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     60\u001b[0m window \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(((window_end_frame \u001b[39m-\u001b[39m window_start_frame) \u001b[39m*\u001b[39m tolerance))\n\u001b[1;32m     61\u001b[0m label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnon_activity\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 62\u001b[0m index \u001b[39m=\u001b[39m bisect\u001b[39m.\u001b[39;49mbisect_right(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_frames, window_start_frame)\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m index \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_frames[index\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m window_start_frame \u001b[39m+\u001b[39m window \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_frames[index\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m     64\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[index\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m3\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save simulated acc data\n",
    "for w_id, dataset in zip(\n",
    "    config.TRAIN_W_IDS + config.VAL_W_IDS + config.TEST_W_IDS,\n",
    "    mmfit.train_datasets.datasets + mmfit.val_datasets.datasets + mmfit.test_datasets.datasets\n",
    "):\n",
    "    real_acc = dataset.acc  # (N, 5)\n",
    "    real_acc_data = real_acc[:, 2:].permute(1, 0)  # (3, N)\n",
    "    pred_acc = torch.empty_like(real_acc_data).to(config.device) # (3, N)\n",
    "    mmfit.unfold(model=pose2imu_model, dataset=dataset, pred_acc=pred_acc)\n",
    "\n",
    "    # save pred_acc\n",
    "    sim_acc = torch.empty_like(real_acc)  # (N, 5)\n",
    "    sim_acc[:, :2] = real_acc[:, :2]\n",
    "    sim_acc[:, 2:] = pred_acc.permute(1, 0)\n",
    "\n",
    "    id_dir = os.path.join(config.mmfit_data_dir, w_id)\n",
    "    np.save(\n",
    "        os.path.join(id_dir, w_id + \"_\" + config.sim_acc_file),\n",
    "        sim_acc.cpu().numpy(),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
